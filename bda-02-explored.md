# 빅데이터분석기사 2021

## 2 빅데이터 탐색

### CHAPTER01 데이터 전처리

#### 1 데이터 정제

##### 1) 데이터 정제

###### (1) 데이터 전처리의 중요성

- 반드시 거쳐야 하는 과정
- 전처리는 반복적으로 수행
- 가장 많은 시간이 소요되는 단계가 데이터 수집과 전처리 단계
- 데이터 정제 > 결측값 처리 > 이상값 처리 > 분석 변수 처리 순으로 진행



###### (2) 데이터 정제(Data Cleansing) 개념

결측값을 채우거나 이상값을 제거하는 과정을 통해 데이터의 신뢰도를 높이는 작업



###### (3) 데이터 정체 절차

1. 오류원인 분석 : 원천 데이터 오류 또는 빅데이터 플로우 문제로 발생 (결측값, 노이즈, 이상값)
2. 데이터 정제 대상 선정 : 모든 데이터가 대상
3. 데이터 정제 방법 결정 : 삭제, 대체, 예측값 삽입



###### (4) 데이터 정제 기술

데이터 일관성을 위한 정제 기법 : 변환(Transform), 파싱(Parsing), 보강(Enhancement)

데이터 정제 기술

- ETL, 맵리듀스(Map Reduce), 스파크/스톰(Spark/Storm), CEP(Complex Event Processing), 피그(Pig), 플럼(Flume)



###### (5) 데이터 세분화

개념

- 데이터를 기준에 따라 나누고, 선택한 매개변수를 기반으로 유사한 데이터를 그룹화하여 효율적으로 사용할 수 있는 프로세스이다.

데이터 세분화 방법

| 방법           | 설명                                                         | 기법                             |
| -------------- | ------------------------------------------------------------ | -------------------------------- |
| 계층적 방법    | 사전에 군집수를 정하지 않고 단계적으로 단계별 군집결과를 산출 | 응집분석법<br>분할분석법         |
| 비 계층적 방법 | 군집을 위한 소집단의 개수를 정해놓고 각 객체 중 하나의 소집단으로 배정 | 인공신경망 모델<br>K-평균 군집화 |



##### 2) 데이터 결측값 처리

###### (1) 데이터 결측값(Data Missing Value) 개념

- 결측값은 입력이 누락된 값
- NA, 999999, NULL 등으로 표현



###### (2) 데이터 결측값 종류

- 완전 무작위 결측(MCAR; Missing Completely At Random)
- 무작위 결측(MAR; Missing At Random)
- 비 무작위 결측(MNAR; Missing Not At Random)

###### (3) 데이터 결측값 처리 절차

1. 결측값 식별 : 현황 파악
2. 결측값 부호화
   - 컴퓨터가 처리 가능한 형태로 부호화
   - NA(Not Available) : 기록되지 않은값
   - NaN(Not a Number) : 수학적으로 정의되지 않은 값
   - inf(infinite) : 무한대
   - NULL : 값이 없음
3. 결측값 대체 : 결측값을 자료형에 맞춰 대체 알고리즘을 통해 결측값을 처리


###### (4) 데이터 결측값 처리 방법

- 단순 대치법

  1. 완전 분석법(Completes Analysis)

  2. 평균 대치법(Mean Imputation)

  3. 단순 확률 대치법(Single Stochastic Imputation)
     1. 핫덱(Hot-Deck) 대체 : 비슷한 성향을 가진 응답자의 자료로 대체. 표본조사에 흔히 사용
     2. 콜드덱(Cold-Deck) 대체 : 핫덱과 비슷하나 대체 자료를 현재 진행 중인 연구에서 얻는것이 아니라 외부 출처 또는 이전의 비슷한 연구에서 가져오는 방법
     3. 혼합 방법 : 몇 가지 다른 방법을 혼합하는 방법

- 다중 대치법

  - 적용방식 : 대치 > 분석 > 결합


##### 3) 데이터 이상값 처리
###### (1)  데이터 이상값(Data Outlier) 개념

- 범위에서 많이 벗어난 아주 작은 값이나 아주 큰 값

###### (2) 데이터 이상값 발생 원인

- 데이터 입력 오류 : 100 입력해야 하는데 1000 입력
- 측정 오류 : 몸무게 측정하는데 9개 체중계 정상, 1개 비정상
- 실험 오류 : 100미터 달리기 하는데, 한 선수가 출발 신호 못 듣고 늦게 출발
- 고의적인 이상값 : 자기 보고식 측정(Self Reported Measures)에서 나타나는 에러. 음주량 조사에서 10대는 보통 음주량을 적게 기입
- 표본추출 에러 : 샘플링을 잘못한 경우. 대학 신입생 키 조사하는데, 농구선수가 포함되어 있는 경우



###### (3) 데이터 이상값 검출 방법

- 개별 데이터 관찰
- 통곗값
- 시각화 : 확률 밀도 함수, 히스토그램, 시계열 차트
- 머신러닝 기법 : K-평균 알고리즘
- 마할라노비스 거리(Mahalanobis Distance) : 관측치가 평균으로 부터 벗어난 정도를 측정하는 통계량 기법
- LOF(Local Outlier Factor) : 관측치 주변 밀도와 근접한 관측치 주변 밀도의 상대적인 비교를 통해 이상값을 탐색하는 기법
- iForest(Isolation Forest) : 의사결정나무(Decisiion Tree)을 이용하여 이상값을 탐지하는 방법

통계기법을 이용한 데이터 이상값 검출 방법

| 검출기법                                  | 설명                                                         |
| ----------------------------------------- | ------------------------------------------------------------ |
| ESD(Extreme Studentized Deviation)        | 평균(&mu;) 으로 부터 3 표준편차(&sigma;) 떨어진 값(각 0.15%)을 이상값으로 판단<br>&mu; - 3&sigma; < data < &mu; + 3&sigma; |
| 기하평균 활용한 방법                      | 기하평균으로부터 2.5표준편차(&sigma;) 떨어진 값을 이상값으로 판단<br> 기하평균 - 2.5 x &sigma; < data < 기하평균 + 2.5 x &sigma; |
| 사분위 수를 이용한 방법                   | 사분위간범위(Q<sub>3</sub> - Q<sub>1</sub>) : IQR 의 1.5배 이상 떨어진 값을 이상값으로 판단 <br> Q<sub>1</sub> - 1.5 x (Q<sub>3</sub> - Q<sub>1</sub>) < data < Q<sub>3</sub> + 1.5 x (Q<sub>3</sub> - Q<sub>1</sub>) |
| 표준화 점수(Z-score)를 활용한 이상값 검출 | 정규분포를 따르는 관측치들이 자료의 중심(평균)에서 얼마나 떨어져 있는지를 나타냄에 따라서 이상값을 검출 |
| 딕슨의 Q 검정(Dixon Q-Test)               | 오름차순 정렬 데이터에서 범위에 대한 관측치 간의 차이의 비율을 활용하여 이상값 여부를 검정하는 방법 <br> 데이터 수가 30개 미만인 경우에 적합 |
| 그럽스 T-검정<br>(Grubbs T-Test)          | 정규분포를 만족하는 단변량 자료에서 이상값을 검정하는 방법   |
| 카이제곱 검정<br>(Chi-Squre Test)         | 데이터가 정규분포를 만족하나, 자료의 수가 적은 경우에 이상값을 검정하는 방법 |

> 단변량 자료(Univariate Data) : 단위에 대해 하나의 속성만 측정하여 얻게 되는 변수에 대한 자료이다.



###### (4) 데이터 이상값 처리

- 이상값을 **반드시 제거**해야 하는 것은 아님. 이상값을 처리할지는 분석의 목적에 따라 적절한 판단이 필요

- 데이터 이상값 처리 기법

  1. 삭제(Deleting Obervations)

     - 기하평균을 이용한 제거

     - 하단, 상단 % 이용한 제거

  2. 대체법(Imputation)
     - ESD를 사용할 경우 상한값은 &mu; + 3&sigma; , 하한값은 &mu; - 3&sigma;
     - 이상값을 평균이나 중앙값으로 대체

  3. 변환(Transformation)
     - 극단적인 이상값 발생 시, 자연로그를 취해서 값을 감소 시키기
     - 상하한값을 벗어나는 값은, 상하한값으로 바꾸어 활용하는 극단값 조정(Winsorizing) 방법도 활용
  4. 박스플롯 해석을 통한 이상값 제거
     - 사분위수를 이용하여 제거, 수염(Whiskers) 밖에 있는 값을 이상값으로 판단
  5. 분류하여 처리
     - 이상값이 많을 경우, 그 이상값을 하나의 그룹으로 묶어 서로 다른 그룹으로 통계적인 분석을 실행하여 처리



