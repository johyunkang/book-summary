# 빅데이터분석기사 2021

## 2 빅데이터 탐색

### CHAPTER01 데이터 전처리

#### 1 데이터 정제

##### 1) 데이터 정제

###### (1) 데이터 전처리의 중요성

- 반드시 거쳐야 하는 과정
- 전처리는 반복적으로 수행
- 가장 많은 시간이 소요되는 단계가 데이터 수집과 전처리 단계
- 데이터 정제 > 결측값 처리 > 이상값 처리 > 분석 변수 처리 순으로 진행



###### (2) 데이터 정제(Data Cleansing) 개념

결측값을 채우거나 이상값을 제거하는 과정을 통해 데이터의 신뢰도를 높이는 작업



###### (3) 데이터 정체 절차

1. 오류원인 분석 : 원천 데이터 오류 또는 빅데이터 플로우 문제로 발생 (결측값, 노이즈, 이상값)
2. 데이터 정제 대상 선정 : 모든 데이터가 대상
3. 데이터 정제 방법 결정 : 삭제, 대체, 예측값 삽입



###### (4) 데이터 정제 기술

데이터 일관성을 위한 정제 기법 : 변환(Transform), 파싱(Parsing), 보강(Enhancement)

데이터 정제 기술

- ETL, 맵리듀스(Map Reduce), 스파크/스톰(Spark/Storm), CEP(Complex Event Processing), 피그(Pig), 플럼(Flume)



###### (5) 데이터 세분화

개념

- 데이터를 기준에 따라 나누고, 선택한 매개변수를 기반으로 유사한 데이터를 그룹화하여 효율적으로 사용할 수 있는 프로세스이다.

데이터 세분화 방법

| 방법           | 설명                                                         | 기법                             |
| -------------- | ------------------------------------------------------------ | -------------------------------- |
| 계층적 방법    | 사전에 군집수를 정하지 않고 단계적으로 단계별 군집결과를 산출 | 응집분석법<br>분할분석법         |
| 비 계층적 방법 | 군집을 위한 소집단의 개수를 정해놓고 각 객체 중 하나의 소집단으로 배정 | 인공신경망 모델<br>K-평균 군집화 |



##### 2) 데이터 결측값 처리

###### (1) 데이터 결측값(Data Missing Value) 개념

- 결측값은 입력이 누락된 값
- NA, 999999, NULL 등으로 표현



###### (2) 데이터 결측값 종류

- 완전 무작위 결측(MCAR; Missing Completely At Random)
- 무작위 결측(MAR; Missing At Random)
- 비 무작위 결측(MNAR; Missing Not At Random)

###### (3) 데이터 결측값 처리 절차

1. 결측값 식별 : 현황 파악
2. 결측값 부호화
   - 컴퓨터가 처리 가능한 형태로 부호화
   - NA(Not Available) : 기록되지 않은값
   - NaN(Not a Number) : 수학적으로 정의되지 않은 값
   - inf(infinite) : 무한대
   - NULL : 값이 없음
3. 결측값 대체 : 결측값을 자료형에 맞춰 대체 알고리즘을 통해 결측값을 처리


###### (4) 데이터 결측값 처리 방법

- 단순 대치법

  1. 완전 분석법(Completes Analysis)

  2. 평균 대치법(Mean Imputation)

  3. 단순 확률 대치법(Single Stochastic Imputation)
     1. 핫덱(Hot-Deck) 대체 : 비슷한 성향을 가진 응답자의 자료로 대체. 표본조사에 흔히 사용
     2. 콜드덱(Cold-Deck) 대체 : 핫덱과 비슷하나 대체 자료를 현재 진행 중인 연구에서 얻는것이 아니라 외부 출처 또는 이전의 비슷한 연구에서 가져오는 방법
     3. 혼합 방법 : 몇 가지 다른 방법을 혼합하는 방법

- 다중 대치법

  - 적용방식 : 대치 > 분석 > 결합


##### 3) 데이터 이상값 처리
###### (1)  데이터 이상값(Data Outlier) 개념

- 범위에서 많이 벗어난 아주 작은 값이나 아주 큰 값

###### (2) 데이터 이상값 발생 원인

- 데이터 입력 오류 : 100 입력해야 하는데 1000 입력
- 측정 오류 : 몸무게 측정하는데 9개 체중계 정상, 1개 비정상
- 실험 오류 : 100미터 달리기 하는데, 한 선수가 출발 신호 못 듣고 늦게 출발
- 고의적인 이상값 : 자기 보고식 측정(Self Reported Measures)에서 나타나는 에러. 음주량 조사에서 10대는 보통 음주량을 적게 기입
- 표본추출 에러 : 샘플링을 잘못한 경우. 대학 신입생 키 조사하는데, 농구선수가 포함되어 있는 경우



###### (3) 데이터 이상값 검출 방법

- 개별 데이터 관찰
- 통곗값
- 시각화 : 확률 밀도 함수, 히스토그램, 시계열 차트
- 머신러닝 기법 : K-평균 알고리즘
- 마할라노비스 거리(Mahalanobis Distance) : 관측치가 평균으로 부터 벗어난 정도를 측정하는 통계량 기법
- LOF(Local Outlier Factor) : 관측치 주변 밀도와 근접한 관측치 주변 밀도의 상대적인 비교를 통해 이상값을 탐색하는 기법
- iForest(Isolation Forest) : 의사결정나무(Decisiion Tree)을 이용하여 이상값을 탐지하는 방법

통계기법을 이용한 데이터 이상값 검출 방법

| 검출기법                                  | 설명                                                         |
| ----------------------------------------- | ------------------------------------------------------------ |
| ESD(Extreme Studentized Deviation)        | 평균(&mu;) 으로 부터 3 표준편차(&sigma;) 떨어진 값(각 0.15%)을 이상값으로 판단<br>&mu; - 3&sigma; < data < &mu; + 3&sigma; |
| 기하평균 활용한 방법                      | 기하평균으로부터 2.5표준편차(&sigma;) 떨어진 값을 이상값으로 판단<br> 기하평균 - 2.5 x &sigma; < data < 기하평균 + 2.5 x &sigma; |
| 사분위 수를 이용한 방법                   | 사분위간범위(Q<sub>3</sub> - Q<sub>1</sub>) : IQR 의 1.5배 이상 떨어진 값을 이상값으로 판단 <br> Q<sub>1</sub> - 1.5 x (Q<sub>3</sub> - Q<sub>1</sub>) < data < Q<sub>3</sub> + 1.5 x (Q<sub>3</sub> - Q<sub>1</sub>) |
| 표준화 점수(Z-score)를 활용한 이상값 검출 | 정규분포를 따르는 관측치들이 자료의 중심(평균)에서 얼마나 떨어져 있는지를 나타냄에 따라서 이상값을 검출 |
| 딕슨의 Q 검정(Dixon Q-Test)               | 오름차순 정렬 데이터에서 범위에 대한 관측치 간의 차이의 비율을 활용하여 이상값 여부를 검정하는 방법 <br> 데이터 수가 30개 미만인 경우에 적합 |
| 그럽스 T-검정<br>(Grubbs T-Test)          | 정규분포를 만족하는 단변량 자료에서 이상값을 검정하는 방법   |
| 카이제곱 검정<br>(Chi-Squre Test)         | 데이터가 정규분포를 만족하나, 자료의 수가 적은 경우에 이상값을 검정하는 방법 |

> 단변량 자료(Univariate Data) : 단위에 대해 하나의 속성만 측정하여 얻게 되는 변수에 대한 자료이다.



###### (4) 데이터 이상값 처리

- 이상값을 **반드시 제거**해야 하는 것은 아님. 이상값을 처리할지는 분석의 목적에 따라 적절한 판단이 필요

- 데이터 이상값 처리 기법

  1. 삭제(Deleting Obervations)

     - 기하평균을 이용한 제거

     - 하단, 상단 % 이용한 제거

  2. 대체법(Imputation)
     - ESD를 사용할 경우 상한값은 &mu; + 3&sigma; , 하한값은 &mu; - 3&sigma;
     - 이상값을 평균이나 중앙값으로 대체

  3. 변환(Transformation)
     - 극단적인 이상값 발생 시, 자연로그를 취해서 값을 감소 시키기
     - 상하한값을 벗어나는 값은, 상하한값으로 바꾸어 활용하는 극단값 조정(Winsorizing) 방법도 활용
  4. 박스플롯 해석을 통한 이상값 제거
     - 사분위수를 이용하여 제거, 수염(Whiskers) 밖에 있는 값을 이상값으로 판단
  5. 분류하여 처리
     - 이상값이 많을 경우, 그 이상값을 하나의 그룹으로 묶어 서로 다른 그룹으로 통계적인 분석을 실행하여 처리



#### 2 분석 변수 처리

##### 1) 변수 선택

###### (1) 변수(Feature) 개념

- 예측을 수행하는데 사용되는 입력변수이다.
- RDBMS에서 '속성(열)' 이라고 부르는 것을 머신러닝에서는 통계학의 영향으로 '변수(Feature)'라고 한다.

변수 명칭

| 유형      | 명칭                                                         |
| --------- | ------------------------------------------------------------ |
| 알려진 값 | **변수(Feature)**, 속성(Attribute), 예측변수(Predictor), **차원(Dimension)**, 관측치(Observation), **독립변수(Independent Variable)** |
| 예측 값   | **라벨(Label)**, 클래스(Class), 목푯값(Target), 반응(Response), **종속변수(Dependent Variable)** |



###### (2)  변수 유형

1. 인과관계
   1. 독립변수
      - 다른 변수에 영향을 받지 않고 종속변수에 영향을 주는 변수
   2. 종속변수
      - 다른 변수로부터 영향을 받는 변수
2. 변수속성
   1. 범주형(Categorical) : 범위와 순서가 있는 변수
      1. 명목형(Nominal)
         - 의미가 없이 이름만 의미를 부여할 수 있는 경우
         - 예) 삼성=1, 엘지=2, 애플=3
      2. 순서형(Ordinal)
         - 순서에 의미를 부여할 수 있는 경우
         - 예) 병원수준(의원=1, 종합병원=2, 대학병원=3), 화장실상태(양호=3, 보통=2, 나쁨=1)
   2. 수치형(Measure) : 수치로 표현되는 변수
      1. 이산형(Discrete)
         - 값을 하나하나 셀 수 있는 경우
         - 예) 틀린 개수, 책의 개수
      2. 연속형(Continuous)
         - 구간 안의 모든 값을 가질 수 있는 경우
         - 예) 몸무게, 키



###### (3) 변수 선택

- 개념 : 독립변수 중 종속변수에 가장 관련성이 높은 변수만을 선정하는 기법
- 특징 : 사용자가 해석하기 쉽게 모델을 단순화해주고, 훈련 시간 축소, 차원의 저주 방지, 과적합(Over-fitting)을 줄여줌
- 변수 선택 기법
  - 필터 기법(Filter Method)
    - 계산 속도가 빠르고 변수 간 상관관계를 알아내는 데 적합
  - 래퍼 기법(Wrapper Method)
    - 가장 좋은 성능을 보이는 하위 집합을 선택하는 기법
    - 하위 집합을 반복해서 선택하여 테스트하므로, 그리디 알고리즘에 적합
    - 시간이 오래 걸리고, 과적합의 위험
    - 필터 방법보다 정확도가 높다

래퍼기법 상세

1. RFE (Recursive Feature Elimination) : SVM(Support Vector Machine)을 사용하여 재귀적으로 제거하는 방법
2. SFS (Sequential Feature Selection) : 그리디 알고리즘으로 특성 변수를 하나씩 추가하는 방법
3. 유전 알고리즘(Genetic Algorithm) : 자연세계의 진화과정에 기초한 계산 모델, 최적화 문제를 해결하는 기법
4. 단변량 선택(Univariate Selection) : 하나의 변수선택법으로, 피처와 반응변수 간 관계의 강도를 결정하는 방법. 데이터에 대한 이해를 높일 때 사용
5. mRMR (Minimum Redundancy Maximum Relevance) : 특성 변수의 중복성을 최소화하는 방법으로 종속변수를 잘 예측하면서, 독립변수들과도 중복성이 적은 변수들을 선택하는 방법



임베디드 기법

- 모델의 정확도에 기여하는 변수를 학습한다.
- 적은 계수를 가지는 회귀식을 찾는 방향으로 제약조건을 주어 이를 제거한다.

임베디드 기법 사례

1. 라쏘(LASSO; Least Absolute Shrinkage and Selection Operator) : 가중치의 절댓값의 합을 최소화하는 것을 추가적인 제약조건으로 하는 방법. L1-norm을 통해 제약을 주는 방법
2. 릿지(Ridge) : 가중치들의 제곱합을 최소화하는 것을 추가적인 제약조건으로 하는 방법. L2-norm을 통해 제약을 주는 방법
3. 엘라스틱 넷(Elastic Net) : 라쏘 와 릿지 두 개를 선형 결합한 방법
4. SelectFromModel : 의사결정나무 기반 알고리즘에서 변수를 선택하는 방법


##### 2) 차원축소

###### (1) 차원축소(Dimensionality Reduction) 개념

- 여러 변수의 정보를 최대한 유지하면서 데이터 세트 변수의 개수를 줄이는 탐색적 분석기법
- 목표변수(y)는 사용하지 않고 특성 변수(설명변수)만 사용하기 때문에 비지도 학습 머신러닝 기법

###### (2) 차원축소 특징

- 전체 데이터의 변수들의 정보를 최대한 유지
- 해당 결합변수만으로도 전체변수를 적절히 설명할 수 있어야 한다.
- 다른 분석과정을 위한 전 단계, 분석 수행 후 개선방법, 또는 효과적인 시각화 등의 목적으로 사용
- 저차원으로 학습할 경우, 회귀나 분류, 클러스터링 등의 머신러닝 알고리즘이 더 잘 작동한다.
- 새로운 저차원 변수(Feature) 공간에서 가시적으로 시각화하기도 쉽다.

###### (3) 차원축소 기법

1. 주성분 분석(PCA: Principal Component Analysis)
   - 변수들의 공분산 행렬이나 상관행렬을 이용
   - 선형 연관성이 없는 저차원 공간으로 변환하는 기법
   - 행의 수와 열의 수가 같은 정방행렬에서만 사용
2. 특이값 분해(SVD: Singular Value Decomposition)
   - M x N 차원의 행렬데이터에서 특이값을 추출하고, 이를 통해 주어진 데이터 세트를 효과적으로 축약할 수 있는 기법
3. 요인분석(Factor Analysis)
   - 데이터 안에 관찰할 수 없는 잠재적인 변수(Latent Variable)가 존재한다고 가정
   - 관찰 가능한 데이터를 이용하여 해당 잠재 요인을 도출하고 데이터 안의 구조를 해석하는 기법
   - 사회과학이나 설문 조사 등에서 활용
4. 독립성분분석(ICA: Independent Component Analysis)
   - 다변량의 신호를 통계적으로 독립적인 하부성분으로 분리하여 차원을 축소하는 기법
   - 비정규 분포를 따르게 되는 차원축소 기법
5. 다차원 척도법(MDS: Multi-Dimensional Scaling)
   - 유사성, 비유사성을 측정하여 2차원 또는 3차원 공간상에 점으로 표현하여 개체들 사이의 집단화를 시각적으로 표현하는 분석 방법

###### (4) 차원축소 기법 주요 활용 분야

- 탐색적 데이터 분석부터 정보 결과의 시각화까지 다양하게 활용되고 있다
- 좀 더 쉽게 데이터를 학습하고 모델을 생성하고자 할 때 주로 활용된다.
- 패턴인식이나 추천시스템 구현 결과의 성능 등을 개선할 때도 사용
- 텍스트 데이터에서 주제나 개념 추출
- 이미지 및 사운드 등의 비정형 데이터에서 특징 패턴 추출
- 판매데이터에서 상품 추천시스템 알고리즘 구현
- 다차원 공간의 정보를 저차원으로 시각화
- 공통 요인(Factor)을 추출하여 잠재된 데이터 규칙 발견


##### 4) 파생 변수(Derived Variance) 생성

파생 변수 생성 방법

- 단위 변환 : 하루 24시간을 12시간으로 변환
- 표현형식 변환 : 남/여 데이터를 0/1 이진수로 변환
- 요약 통계량 변환 : 고객별 누적 방문 횟수 집계
- 변수 결합 : 매출액과 방문 횟수 데이터로 1회 평균 매출액 추출

##### 5) 변수 변환(Variable Transformation)

변수 변환 방법

1. 단순 기능 변환(Simple Function)
   - 한 쪽으로 치우친 변수를 변환하여 분석 모형을 적합하게 하는 방법
   - 예) 로그변환($\log$$x$), 역수 변환(1/x), 루트변환($\sqrt x$), 제곱 변환($x$^2^)

2. 비닝(Binning)
   - 기존 데이터를 범주화하기 위해 사용
   - 두 개 이상의 변수의 값에 따라 공변량 비닝(co-variate binning) 수행
   - 예) 수입을 상,중,하의 범주로 나누기
3. 정규화(Normalization)
   - 데이터를 특정 구간으로 바꾸는 척도법
   - 최소-최대 정규화, Z-스코어 정규화 유형이 있음
   - 예) 최소-최대 정규화 $x - x~min~ \over x~max~ - x~min~$
4. 표준화
   - 데이터를 0을 중심으로 양쪽으로 데이터를 분포시키는 방법
   - 표준화와 정규화는 데이터 전처리에서 상호 교환하여 사용
   - 예) Z-스코어 정규화 : Z = $x - X \over s$   : X: 평균, s: 표준편차


##### 5) 불균형 데이터 처리

- 탐색하는 데이터의 수가 매우 극소수인 경우에 불균형 데이터 처리를 한다.

불균형 데이터 처리 기법

1. 언더 샘플링(Under-Sampling)
   - 다수 클래스의 데이터를 일부만 선택하여 데이터의 비율을 맞추는 방법
   - 데이터의 소실이 매우 크고, 중요한 정상 데이터를 잃을 수 있다.
   - 대표 기법에는 랜덤 언더 샘플링, ENN(Edited Nearest Neighbours), 토멕 링크 방법(Tomek Link Method), CNN(Condensed Nearest Neighbor), OSS(One Sided Selection) 등이 있다.
2. 오버 샘플링(Over-Sampling)
   - 소스 클래스의 데이터를 복제 또는 생성하여 데이터의 비율을 맞추는 방법으로 과대 샘플링이라고도 한다.
   - 과적합(Over-fitting)을 초래할 수 있다.
   - 알고리즘의 성능은 높으나 검증의 성능은 나빠질 수 있다.
   - 대표적인 기법에느 랜덤 오버 샘플링, SMOTE(Synthetic Minority Over-sampling TEchnique), Borderline-SMOTE, ADASYN(ADAptive SYNthetic) 등이 있다.
3. 임곗값 이동(Threshold-Moving)
   - 임곗값을 데이터가 많은 쪽으로 이동시키는 방법
   - 학습 단계에서는 변화 없이 학습하고 테스트 단계에서 임곗값을 이동한다.
   - 예) 양성 90개, 음성 10개 데이터 샘플이 있다.
     - 언더 샘플링 : 양성 클래스의 샘플을 10개로 만들기
     - 오버 샘플링 : 음성 클래스의 샘플을 90개로 만들기
     - 임곗값 이동 : 분류 시행할 때 사용되는 임곗값을 양성과 음성의 비율로 조정
4. 앙상블 기법(Ensemble Technique)
   - 앙상블은 같거나 서로 다른 여러 가지 모형들의 예측/분류 결과를 종합하여 최종적인 의사결정에 활용하는 기법
   - 오버 샘플링, 언더 샘플링, 임곗값 이동을 조합한 앙상블을 만들 수 있다.
   - 앙상블의 예측 중에서 가장 많은 표를 받은 클래스를 최종적으로 선택한다.


### CHAPTER02 데이터 탐색

#### 1 데이터 탐색 기초

##### 1) 데이터 탐색 개요

###### (1) 데이터 탐색의 개념

- 그래프나 통계적인 방법을 이용하여 다양한 각도에서 데이터의 특징을 파악하고 자료를 직관적으로 바라보는 분석 방법
- 데이터 탐색의 도구로는 도표, 그래프, 요약 통계를 이용

###### (2) 탐색적 데이터 분석(EDA: Exploratory Data Analysis)의 4가지 주제(특징)

1. 저항성(Resistance)
   - 저항성은 수집된 자료에 오류점, 이상값이 있을 때에도 영향을 적게 받는 성질을 의미
   - 데이터의 부분적 변동에 민감하게 반응하지 않음
   - 탐색적 데이터 분석은 저항성이 큰 통계적 데이터를 이용
   - 예) EDA 에서는 평균보다 저항성이 큰 중위수(Median)를 대푯값으로 선호
2. 잔차 해석(Residual)
   - 관찰 값들이 주 경향으로 부터 얼마나 벗어난 정도
   - 잔차를 구해봄으로써 데이터의 보통과 다른 특징을 탐색
   - 주 경향에서 벗어난 값이 왜 존재하는지에 대해 탐색하는 작업
3. 자료 재표현(Re-expression)
   - 데이터 분석과 해석을 단순화할 수 있도록 원래 변수를 적당한 척도(로그변환, 제곱근 변환, 역수 변환 등)로 바꾸는 것
   - 데이터 구조파악과 해석에 도움을 얻는 경우가 많음
4. 현시성(Graphic Representation)
   - Display, Visualization, 데이터 시각화로도 불림
   - 데이터 분석 결과를 쉽게 이해할 수 있도록 시각적으로 표현하고 전달하는 과정을 의미



###### (3) 개별 변수 탐색 방법

- 범주형 데이터(질적 데이터)
  - 명목 척도(Nominal Scale)와 순위 척도(Ordinal Scale)에 대한 데이터 탐색
  - 빈도수, 최빈값, 백분율 등을 이용하여 데이터의 분포 특성을 중심성, 변동성 측면에서 파악
  - 시각화는 막대형 그래프(Bar plot)을 주로 이용
- 수치형 데이터(양적 데이터)
  - 등간 척도(Interval Scale)와 비율 척도(Ratio Scale)에 대한 데이터 탐색
  - 평균, 분산, 표준편차 등을 이용하여 데이터의 분포 특성을 파악
  - 시각화는 박스플롯이나 히스토그램 주로 이용

###### (4) 다차원 데이터 탐색

다차원 데이터 탐색 방법

- 범주형 - 범주형
  - 비율, 백분율 분석 등을 활용하여 데이터 간의 연관성을 분석
  - 시각화는 막대형 그래프(Bar Plot)을 주로 이용
- 수치형 - 수치형
  - 산점도와 기울기를 통하여 변수 간의 상관성을 분석
  - 산점도를 이용하여 시각화
  - 공분산을 통하여 방향성 파악
  - 피어슨(Pearson) 상관계수를 통하여 방향성과 강도 파악
- 범주형 - 수치형
  - 범주형 데이터의 항목들을 그룹으로 간주하고 각 그룹에 따라 수치형 변수의 기술 통계량 차이를 상호 비교
  - 그룹 간 비교를 위하여 주로 박스 플롯을 이용하여 시각화



##### 2) 상관관계 분석

###### (1) 상관관계 분석(Correlation Analysis)의 개념

- 두 개 이상의 변수 사이에 존재하는 상호 연관성의 존재 여부와 연관성의 강도를 측정하여 분석하는 방법
- 예) 광고비 지출이 매출액의 증가에 어느 정도의 영향이 있는지를 파악할 때 사용하는 방법

###### (2) 변수 사이의 상관관계의 종류

양(+)의 상관관계, 음(-)의 상관관계, 상관관계 없음

###### (3) 상관관계 표현 방법

1. 산점도(Scatter Plot)를 통한 표현
2. 공분산을 통한 표현 방법
   - 개념 : 2개의 변수 사이의 상관 정도를 나타내는 값
   - 특징 : 상관관계의 상승 혹은 하강하는 경향을 이해할 수 있다. 값의 크기는 측정 단위에 따라 달라지므로 선형관계의 강도를 나타내지는 못한다.

###### (4) 상관관계 분석의 분류

변수의 개수에 따른 상관성 분석 방법의 분류

- 단순 상관 분석
  - 두 개의 변수 사이의 상관성 분석
  - 예) 나이와 급여 사이의 상관성 분석
- 다중 상관 분석
  - 세 개 이상의 변수 사이의 상관성 분석
  - 예) 직위, 나이, 급여 사이의 상관성 분석



변수의 속성에 따른 상관성 분석 방법의 분류

1. 수치적 데이터
   - 수치형 데이터인 등간 척도, 비율 척도에 해당
   - 수치로 표현할 수 있는 측정 가능한 데이터 변수 ( 예. 나이, 몸무게, 이동 거리)
   - 변수의 연산이 가능 ( 예. 이동거리의 평균)
   - 분선 방법 : 피어슨(Pearson) 상관계수
2. 순서적 데이터
   - 범주형 데이터 중에서 순서적 데이터에 해당
   - 데이터 순서에 의미를 부여한 데이터 변수 (예. 성적 순위(1, 2, 3등), 학력(고졸, 중졸, 대졸))
   - 변수의 연산이 불가능 (예. 고졸 + 중졸 = 대졸 로 표현 불가능)
   - 분석 방법 : 스피어만(Spearman) 순위 상관 분석
3. 명목적 데이터
   - 범주형 데이터 중에서 명목척도에 해당
   - 데이터 특성을 구분하기 위하여 숫자나 기호를 할당한 데이터 (예 성별(남/여), 학반(1반, 2반, 3반))
   - 변수의 연산이 불가능 (예. 1반 + 2반 = 3반으로 표현 불가능)
   - 분석 방법 : 카이제곱(X^2^)검정 (교차 분석)



##### 3) 기초통계량 추출 및 이해

###### (1) 중심 경향성 통계량

1. 평균(Mean)
   - 이상값에 의해 변동이 심하게 변할 수 있다
2. 중위수(Median)
   - 모든 데이터 값을 오름차순으로 정렬하였을 때 중앙에 위치한 데이터 값, 중앙값이라고도 한다.
3. 최빈값(Mode)
   - 주어진 데이터 중에서 가장 많이 관측되는 수

###### (2) 산포도의 통계량

1. 범위(Range)
   - 최대값(Max)과 최소값(Min) 사이의 차이이다. 범위 = Max - Min
2. 분산(Variance)
   - 데이터가 평균으로 부터 흩어진 정도를 나타내는 통계량
   - 편차(데이터 - 평균)의 합은 0이므로 편차의 제곱의 합을 이용하여 계산
   - 모분산은 편차의 제곱의 합을 모집단의 수(N)로 나누어 주고, 표본분산은 표본의 수에서 1을 뺀 자유도(n-1)로 나누어 계산한다.
3. 표준편차(Standard Deviation)
   - 분산의 양(+)의 제곱근의 값
4. 변동계수(CV: Coefficient of Variation)
   - 측정 단위가 서로 다른 자료의 흩어진 정도를 상대적으로 비교할 때 사용
   - 상대 표준편차라고도 한다.
   - 표준편차를 표본평균으로 나눈 값으로서 값이 클수록 상대적인 차이가 크다.
5. 사분위 수 범위(IQR : Inter Quartile Range)
   - 사분위 수 범위는 1사분위 수(Q1)과 3사분위 수(Q3) 사이의 차이이다.
   - 예) 1,5,8,9,13,17,19   (Q1=5, Q2=9, Q3=17, IQR = 17 - 5 = 12)

###### (3) 데이터의 분포를 나타내는 통계량

1. 왜도(Skewness)
   - 데이터의 분포가 정규 분포로부터 오른쪽 또는 왼쪽으로 치우친 정도를 보여주는 값
   - 왜도 종류
     - 왼쪽 편포(Skewed to the left) : 평균(Mean) < 중위수(Median) < 최빈값(Mode)
     - 왼쪽 편포의 왜도는 0보다 작음
     - 오른쪽 편포(Skewed to the right) : 최빈값 < 중위수 < 평균
     - 오른쪽 편포의 왜도는 0보다 큼
2. 첨도(Kurtosis)
   - 데이터의 분포가 정규 분포 곡선으로 부터 위 또는 아래쪽으로 뾰족한 정도를 보여주는 값
   - 정규 분포는 첨도가 0 이지만, 일반적으로 첨도의 정의에서 3을 뺀 0을 기준으로 하고 있다. 따라서 이 책의 정규 분포의 첨도를 0으로 한다.
   - 뾰족한 정규분포(첨도>0), 낮은 정규분포(첨도 < 0)



##### 4) 시각적 데이터 탐색

###### (1) 히스토그램

- 개념 : 자료 분포의 형태를 직사각형 형태로 시각화하여 보여주는 그래프
- 특징
  - 가로축은 수치형 데이터
  - 막대는 서로 붙어 있다.
  - 막대 넓이는 일정하다.

###### (2) 막대형 그래프(Barplot)

- 개념 : 항목들에 대한 많고 적음을 비교하기 쉽도록 수량을 막대의 길이로 표현하는 그래프
- 특징
  - 가로축은 수치형 데이터가 아니어도 된다.
  - 막대는 서로 떨어져 있다.
  - 막대 넓이는 같지 않을 수 있다.

###### (3) 박스 플롯(Boxplot)

- 개념 : 집합의 범위와 중앙값을 빠르게 확인할 수 있으며, 통계적으로 이상값이 있는지 빠르게 확인이 가능한 시각화 기법
- 구성요소 : 하위 경계(1사분위에서 1.5IQR을 뺀 위치), 최솟값, Q1, Q3, 수염(Whiskers : Q1, Q3로 부터 1.5배 내에 가장 멀리 떨어진 데이터까지 이어진 선), 이상값(Outlier: 수염보다 바깥쪽에 있는 데이터)

###### (4) 산점도(Scatter Plot)

- 가로축과 세로축의 좌표평면상에서 각각의 관찰점들을 표시하는 시각화 방법
- 2개의 연속형 변수 간의 관계를 보기 위하여 사용된다.


#### 2 고급 데이터 탐색

##### 1) 시공간 데이터 탐색

###### (1) 시공간 데이터

- 개념 : 공간적 객체에 시간의 개념이 추가되어 시간에 따라 위치나 형상이 변하는 데이터
- 특징 : 데이터를 공간과 시간의 흐름상에위치시킬 수 있는 거리 속성과 시간 속성을 가지고 있다.
- 시공간 데이터 타입
  - 포인트 타입 : 하나의 노드로 구성되는 공간 데이터 타입
  - 라인 타입 : 서로 다른 두개의 노드와 두 노드를 잇는 하나의 세그먼트로 구성
  - 폴리곤 타입 : n개(n>=3)의 노드와 n개의 세그먼트로 구성
  - 폴리라인 타입 : n개(n>=3)의 노드와 n-1개의 세그먼트로 구성

###### (2) 시공간 데이터 탐색 절차

- 주소를 행정구역으로 변환
- 주소를 좌표계로 변환
  - 지오코딩(Geo-Coding) 서비스를 이용하여 좌표계로 변환
- 행정구역 및 좌표계를 지도에 표시
  - 코로플레스 지도, 카토그램, 버블 플롯맵 등이 있다.

##### 2) 다변량 데이터 탐색

###### (1) 다변량 데이터

- 개념 : 조사 대상의 특징, 성질을 숫자 또는 문자로 나타낸 값. 일변량, 이변량, 다변량으로 구분
- 변량 데이터 유형
  - 일변량 데이터 : 단위에 대해 하나의 속성만 측정하여 얻게 되는 변수에 대한 자료로 단변량 자료라고도 함
  - 이변량 데이터 : 각 단위에 대해 두 개의 특성을 측정하여 얻어진 두 개의 변수에 대한 자료
  - 다변량 데이터 : 하나의 단위에 대해 두 가지 이상의 특성을 측정하는 경우 얻어지는 변수에 대한 자료. 이변량 데이터도 다변량 데이터이다.

###### (2) 변량 데이터 탐색

- 일변량 데이터 탐색
  - 기술 통계량, 그래프 통계량 두 가지 종류가 있음
  - 기술 통계량에는 평균, 분산, 표준편차, 그래프 통계량에는 히스토그램, 상자 그림 등이 있다.
- 이변량 데이터 탐색
  - 두 변수 사이의 관계를 밝히려는 것이 관심의 대상임
- 다변량 데이터 탐색
  - 분석을 시행하기 이전에 산점도 행렬, 별 그림, 등고선 그림 등을 통해 시각적으로 자료를 탐색함

###### (3) 다변량 데이터 탐색 도구

1. 산점도 행령
2. 별 그림



##### 3) 비정형 데이터 탐색

###### (1) 비정형 데이터(Unstructured Data)의 개념

- 이미지나 영상, 텍스트처럼 형태와 구조가 다른 구조화 되지 않은 데이터

###### (2) 비정형 데이터 유형

- 비정형 데이터
  - 텍스트 : 텍스트 덩어리를 정형 데이터로 변환한 뒤 텍스트 분석을 수행
  - 이미지 : 한 픽셀마다 수치로 변환하는 과정을 거쳐 이미지 분석을 시행. 최근에는 딥러닝 기법의 하나인 CNN이 주로 쓰임
- 반정형 데이터
  - XML
  - JSON
  - HTML

> CNN(Convolutional Neural Network) : 시각적 이미지를 분석하는데 사용되는 심층신경망으로 합성 곱 신경망이라고도 한다.

###### (3) 비정형 데이터 탐색 방법

- 텍스트 탐색 : 데이터를 파싱한 후 탐색
- 동영상, 이미지 탐색 : 데이터의 종류별로 응용소프트웨어를 이용하여 탐색
- XML, JSON, HTML 탐색 방법 : 각각의 파서(Parser)를 이용하여 데이터를 파싱 후 탐색

###### (4) 비정형 데이터 탐색 플랫폼 구성 예시

- HDFS
- 맵리듀스
- 주키퍼
- Avro
- Hive
- Pig
- HCatalog


### CHAPTER03 통계기법 이해
#### 1 기술통계
##### 1) 데이터 요약
###### (1) 기초 통계량

1. 평균(Mean)
   - 전부 같은 가중치, 이상값에 민감한 단점
   - 표본평균, 모평균, 가중평균이 있다
   - 표본은 조사하는 모집단의 일부
2. 중위수(Median)
   - 오름차순 정렬하였을 때 중앙에 위치한 값, 중앙값이라고도 한다.
   - 특이값에 영향 받지 않음
   - 데이터 수가 홀수일 경우 중위수가 하나가 되지만, 짝수인 경우 중앙에 위치한 두개의 값을 평균하여 중위수를 구함
3. 최빈값(Mode)
   - 데이터 중 빈도수가 가장 높은 데이터값
   - 가장 많이 관측되는 수
4. 범위(Range)
   - 최대값(Max)과 최소값(Min) 사이의 차이이다.
   - 범위(Range) = 최대 데이터값(Max) - 최소 데이터값(Min)
5. 분산(Variance)
   - 데이터가 평균으로 부터 흩어진 정도
   - 표분 분산 : 더한 값을 (n-1)로 나눔
   - 모분산: 모집단은 n으로 나눔. 모집단에 대한 분산은 &sigma;<sup>2</sup>으로 정의
6. 표준편차(Standard Deviation)
   - 분산에 양의 제곱근을 취한 값
7. 평균의 표준 오차(Standard Error of Mean)
   - 표본 평균의 표본 추출 분포에 대한 표준편차이다.
8. 분포(Distribution)
   - 데이터 분포의 형태와 대칭성을 설명할 수 있는 통계량에는 첨도와 왜도가 있다.
   - 첨도(Kurtosis)
     - 데이터 분포의 '뾰족한 정도'를 설명하는 통계량
     - 첨용: 첨도 > 0. 첨도가 0보다 큰 분포
     - 평용 : 첨도 < 0. 첨도가 0보다 작은 분포
   - 왜도(Skewness)
     - 데이터 분포의 '기울어진 정도'를 설명하는 통계량. 비대칭성을 나타내는 통계량
     - 왜도 > 0. 우측으로 긴 꼬리
     - 왜도 < 0, 좌측으로 긴 꼬리



###### (2) 상관 분석

- 분석방법
  - 단순상관 분석 : 두 변수 사이의 연관 정보를 알아내는 분석
  - 다중상관 분석 : 셋 또는 그 이상의 변수들 사이의 연관 정도를 분석
- 상관분석의 종류
  1. 수치적 데이터 변수의 상관 분석
     - 일반적으로 피어슨 상관계수를 선형고나련성 정도로 측정하는 척도로 사용
     - r값 : 0.7 <= r <= 1 : X와 Y간에 강한 양적 선형관계
     - r값 : -1 <= r <= -0.7 : X와 Y간에 강한 음적 선형관계
  2. 명목적 데이터 변수의 상관 분석
     - 항목들을 분류하기 위한 명목적 데이터 변수들로 이루어진 두 변수 간의 연관성을 계량적으로 파악하기 위한 통계적 기법
     - 명목적 데이터 변수 간의 상관계수를 계산하는 것이 큰 의미가 없다
  3. 순서적 데이터 변수의 상관 분석
     - 순서가 중요한 의미가 있는 순서적 데이터 변수들로 이루어진 두 변수 간의 연관성 및 상관관계를 검정하기 위한 통계적 분석기법
     - 스피어만 순위상관계수(Spearman's Rank Correlation Coefficient)를 통해서 분석을 수행



###### (3) 회귀 분석

- 회귀 분석(Regression Analysis) 개념 : 하나 이상의 독립변수들이 종속변수에 미치는 영향을 추정할 수 있는 통계기법

- 회귀 분석 전제조건

  | 전제조건 | 설명                                                         |
  | -------- | ------------------------------------------------------------ |
  | 선형성   | 독립변수와 종속변수 간에는 선형관계가 존재                   |
  | 등분산성 | 잔차(추정오차)들은 같은 분산을 가짐                          |
  | 독립성   | 잔차와 독립변수의 값이 관련돼 있지 않음                      |
  | 비상관성 | 관측치들의 잔차들끼리 상관이 없어야 함                       |
  | 정규성   | 잔차는 평균이 0이고 분산이 &sigma;<sup>2</sup> 인 정규 분포를 따름 |

###### (4) 분산 분석

- 분산분석(ANOVA; Analysis of Variance) 개념

  두 개 이상의 집단 간 비교를 수행하고자 할 때 집단 내의 분산, 총 평균과 각 집단의 평균 차이에 의해 생긴 집단 간 분산 비교로 얻은 F-분포를 이용하여 가설검정을 수행하는 방법이다.

- 특징

  분산 분석은 복수의 집단을 비교할 때 분산을 계산함으로써 집단 간에 통계적인 차이가 있다고 할 수 있는지, 혹은 차이가 없다고 할 수 있는지를 판정하는 분석 방법

###### (5) 주성분 분석

- 주성분 분석(PCA; Principal Component Analysis) 개념

  많은 변수의 분산방식(분산.공분산)의 패턴을 간결하게 표현하는 주성분 변수를 원래 변수의 선형 결합으로 추출하는 통계기법이다.

- 특징

  주성분 변수는 원래 변수 정보를 축약한 변수이며, 일부 주성분에 의해 원래 변수의 변동이 충분히 설명되는지 알아보는 분석 방법이다.

  P개의 변수가 있는 경우 이를 통해 얻은 정보를 P보다 상당히 적은 K개의 변수로 요약하는 것이다.

###### (6) 판별 분석

- 판별 분석(Discriminant Analysis) 개념

  집단에 대한 정보로 부터 집단을 구별할 수 있는 판별규칙 혹은 판별함수를 만들고, 단변량 기법으로 조사된 집단에 대한 정보를 활용하여 새로운 개체가 어떤 집단인지를 탐색하는 통계기법
  
  
  


##### 2) 표본 추출

###### (1) 표본 추출 기법

1. 단순 무작위 추출(Simple Random Sampling)
   - 모집단에서 정해진 규칙없이 표본을 추출하는 방식
   - 예) 100개의 전구에서 무작위로 10개의 전구를 추출
2. 계통 추출(Systematic Sampling)
   - 모집단을 일정한 간격으로 추출하는 방식
   - 예) 100명의 사람에게 번호표를 나눠주고 끝자리가 7로 끝나는 사람들을 선정
3. 층화 추출(Stratified Random Sampling)
   - 모집단을 여러 계층으로 나누고, 계층별로 무작위 추출을 수행한느 방식
   - 계층은 내부적으로 동질적이고, 외부적으로 이질적이어야 함
   - 예) 지역별 여론조사를 위해 조사 지역을 도별로 나누고, 각 도에서 무작위로 100명씩 선정
4. 군집 추출(Cluster Sampling)
   - 모집단을 여러 군집으로 나누고, 일부 군집의 전체 또는 일부를 추출하는 방식
   - 계층과는 다르게 군집의 성질은 따로 고려되지 않음
   - 예) 100개의 전구에서 무작위로 검은색, 노란색, 파란색을 칠하고 파란색의 전구를 모두 추출

###### (2) 자료 측정(Measurement)

관계를 부여하기 위해 사용되는 규칙을 척도(Scale)라고 한다.

1. 질적 속성
   - 명목 척도(Nominal Scale)
     - 단순히 집단의 분류를 목적으로 사용된 척도. 등호연산(=. !=)
     - 예) 이메일 주소, 인터넷 계정, 옷 색깔, 성별
   - 순서 척도(Ordinal Scale)
     - 측정대상 사이의 대소 관계를 나타내기 위한 척도
     - 비교 연산(<, >)
     - 예) 직급, 영화 평점, 선호도
2. 양적 속성
   - 구간 척도(Interval Scale)
     - 등간 척도라고도 하며, 서열과 의미 있는 차이를 가지는 척도
     - 예) 온도, 지능지수
   - 비율 척도(Ratio Scale)
     - 구간 척도의 성질을 가지면서 척도 간의 비(Ratio)도 의미가 있는 척도
     - 승제 연산(X, /)
     - 예) 질량, 나이, 개수, 길이





  
