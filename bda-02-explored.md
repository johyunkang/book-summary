# 빅데이터분석기사 2021

## 2 빅데이터 탐색

### CHAPTER01 데이터 전처리

#### 1 데이터 정제

##### 1) 데이터 정제

###### (1) 데이터 전처리의 중요성

- 반드시 거쳐야 하는 과정
- 전처리는 반복적으로 수행
- 가장 많은 시간이 소요되는 단계가 데이터 수집과 전처리 단계
- 데이터 정제 > 결측값 처리 > 이상값 처리 > 분석 변수 처리 순으로 진행



###### (2) 데이터 정제(Data Cleansing) 개념

결측값을 채우거나 이상값을 제거하는 과정을 통해 데이터의 신뢰도를 높이는 작업



###### (3) 데이터 정체 절차

1. 오류원인 분석 : 원천 데이터 오류 또는 빅데이터 플로우 문제로 발생 (결측값, 노이즈, 이상값)
2. 데이터 정제 대상 선정 : 모든 데이터가 대상
3. 데이터 정제 방법 결정 : 삭제, 대체, 예측값 삽입



###### (4) 데이터 정제 기술

데이터 일관성을 위한 정제 기법 : 변환(Transform), 파싱(Parsing), 보강(Enhancement)

데이터 정제 기술

- ETL, 맵리듀스(Map Reduce), 스파크/스톰(Spark/Storm), CEP(Complex Event Processing), 피그(Pig), 플럼(Flume)



###### (5) 데이터 세분화

개념

- 데이터를 기준에 따라 나누고, 선택한 매개변수를 기반으로 유사한 데이터를 그룹화하여 효율적으로 사용할 수 있는 프로세스이다.

데이터 세분화 방법

| 방법           | 설명                                                         | 기법                             |
| -------------- | ------------------------------------------------------------ | -------------------------------- |
| 계층적 방법    | 사전에 군집수를 정하지 않고 단계적으로 단계별 군집결과를 산출 | 응집분석법<br>분할분석법         |
| 비 계층적 방법 | 군집을 위한 소집단의 개수를 정해놓고 각 객체 중 하나의 소집단으로 배정 | 인공신경망 모델<br>K-평균 군집화 |



##### 2) 데이터 결측값 처리

###### (1) 데이터 결측값(Data Missing Value) 개념

- 결측값은 입력이 누락된 값
- NA, 999999, NULL 등으로 표현



###### (2) 데이터 결측값 종류

- 완전 무작위 결측(MCAR; Missing Completely At Random)
- 무작위 결측(MAR; Missing At Random)
- 비 무작위 결측(MNAR; Missing Not At Random)

###### (3) 데이터 결측값 처리 절차

1. 결측값 식별 : 현황 파악
2. 결측값 부호화
   - 컴퓨터가 처리 가능한 형태로 부호화
   - NA(Not Available) : 기록되지 않은값
   - NaN(Not a Number) : 수학적으로 정의되지 않은 값
   - inf(infinite) : 무한대
   - NULL : 값이 없음
3. 결측값 대체 : 결측값을 자료형에 맞춰 대체 알고리즘을 통해 결측값을 처리


###### (4) 데이터 결측값 처리 방법

- 단순 대치법

  1. 완전 분석법(Completes Analysis)

  2. 평균 대치법(Mean Imputation)

  3. 단순 확률 대치법(Single Stochastic Imputation)
     1. 핫덱(Hot-Deck) 대체 : 비슷한 성향을 가진 응답자의 자료로 대체. 표본조사에 흔히 사용
     2. 콜드덱(Cold-Deck) 대체 : 핫덱과 비슷하나 대체 자료를 현재 진행 중인 연구에서 얻는것이 아니라 외부 출처 또는 이전의 비슷한 연구에서 가져오는 방법
     3. 혼합 방법 : 몇 가지 다른 방법을 혼합하는 방법

- 다중 대치법

  - 적용방식 : 대치 > 분석 > 결합


##### 3) 데이터 이상값 처리
###### (1)  데이터 이상값(Data Outlier) 개념

- 범위에서 많이 벗어난 아주 작은 값이나 아주 큰 값

###### (2) 데이터 이상값 발생 원인

- 데이터 입력 오류 : 100 입력해야 하는데 1000 입력
- 측정 오류 : 몸무게 측정하는데 9개 체중계 정상, 1개 비정상
- 실험 오류 : 100미터 달리기 하는데, 한 선수가 출발 신호 못 듣고 늦게 출발
- 고의적인 이상값 : 자기 보고식 측정(Self Reported Measures)에서 나타나는 에러. 음주량 조사에서 10대는 보통 음주량을 적게 기입
- 표본추출 에러 : 샘플링을 잘못한 경우. 대학 신입생 키 조사하는데, 농구선수가 포함되어 있는 경우



###### (3) 데이터 이상값 검출 방법

- 개별 데이터 관찰
- 통곗값
- 시각화 : 확률 밀도 함수, 히스토그램, 시계열 차트
- 머신러닝 기법 : K-평균 알고리즘
- 마할라노비스 거리(Mahalanobis Distance) : 관측치가 평균으로 부터 벗어난 정도를 측정하는 통계량 기법
- LOF(Local Outlier Factor) : 관측치 주변 밀도와 근접한 관측치 주변 밀도의 상대적인 비교를 통해 이상값을 탐색하는 기법
- iForest(Isolation Forest) : 의사결정나무(Decisiion Tree)을 이용하여 이상값을 탐지하는 방법

통계기법을 이용한 데이터 이상값 검출 방법

| 검출기법                                  | 설명                                                         |
| ----------------------------------------- | ------------------------------------------------------------ |
| ESD(Extreme Studentized Deviation)        | 평균($\mu$) 으로 부터 3 표준편차($\sigma$) 떨어진 값(각 0.15%)을 이상값으로 판단<br>$\mu$ - 3$\sigma$ < data < $\mu$ + 3$\sigma$ |
| 기하평균 활용한 방법                      |                                                              |
| 사분위 수를 이용한 방법                   |                                                              |
| 표준화 점수(Z-score)를 활용한 이상값 검출 |                                                              |
| 딕슨의 Q 검정(Dixon Q-Test)               |                                                              |
| 그럽스 T-검정<br>(Grubbs T-Test)          |                                                              |
| 카이제곱 검정<br>(Chi-Squre Test)         |                                                              |


