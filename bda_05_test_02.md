## 빅분기 필기 시험 2회

### 4. 다음 중 다음 그림과 같은 빅데이터 조직 구조로 가장 적절한 것은 무엇인가?

![team-gujo](https://user-images.githubusercontent.com/291782/132188085-72e7a511-14ed-466f-9f60-dd6df8615e91.png)

1. 집중 구조 2.기능 구조 3. 분산 구조 4. 협업 구조



- 조직 구조에는 집중, 기능, 분산 구조가 있다.
- 기능 구조는 일반적인 형태로 별도 분석 조직이 없고, 해당 부서에서 분석 수행한다.
- ![bigdata-team-gujo](https://user-images.githubusercontent.com/291782/132188755-1dee7a3f-3191-4ed3-8f27-ff18d5ab0dde.png)
- DSCoE : Data Science Center of Excellence는 데이터 사이언스 전문가 조직이다.



### 5. 다음 빅데이터 플랫폼 구성요소 중 데이터 수집에 해당하는 것으로 가장 적절한 것은 무엇인가?

1. RDBMS 2.EAI 3.SNS분석 4.인포그래픽

- 빅데이터 플랫폼 구성요소에는 데이터 수집, 저장, 분석, 활용이 있다.

- 데이터 수집에는 ETL, 클로러, EAI 등이 있다.

- |  구성요소   | 주요기능                                                     |
  | :---------: | :----------------------------------------------------------- |
  | 데이터 수집 | 원천 데이터의 정형/반정형/비정형 데이터 수집<br>ETL, 크롤러, EAI(Enterprise Architecture Integration) 등 |
  | 데이터 저장 | 정형 데이터, 반정형 데이터, 비정형 데이터 저장<br>RDBMS, NoSQL 등 |
  | 데이터 분석 | 텍스트 분석, 머신러닝, 통계, 데이터 마이닝<br>SNS 분석, 예측 분석 등 |
  | 데이터 활용 | 데이터 가시화 및 BI, Open API 연계<br>히스토그램, 인포그래픽 등 |

> EAI : (Enterprise Architecture Integration) : 기업에서 운영하는 서로 다른 기종의 애플리케이션 및 시스템을 통합하는 솔루션



### 7. 다음 중 정보통신망을 통하여 수집, 처리, 보관, 이용되는 개인정보의 보호에 관한 규정 법령으로 가장 적절한 것은 무엇인가?

1. 개인정보 보호법 2. 정보통신망법 3.신용정보법 4.위치정보법

- 정보통신망을 통하여 수집, 처리, 보관, 이용되는 개인정보보호에 관한 규정 법령은 정보통신망법이다.

- 개인정보보호 관련 법령

- |            관련 법규            | 주요 내용                                                    |
  | :-----------------------------: | ------------------------------------------------------------ |
  |         개인정보 보호법         | 개인정보 처리 과정상의 정보 주체와 개인정보 처리자의 권리, 의무 등 규정 |
  |          정보통신망법           | '정보통신망 이용촉진 및 정보보호 등에 관한 법률'의 약칭<br>정보통신망을 통하여 수집, 처리, 보관, 이용되는 개인정보의 보호에 관한 규정 |
  |           신용정보법            | '신용정보의 이용 및 보호에 관한 법률'의 약칭<br>개인 신용정보의 취급 단계별 보호조치 및 의무사항에 관한 규정 |
  |           위치정보법            | '위치정보의 보호 및 이용 등에 관한 법률'의 약칭<br>개인 위치정보 수집, 이용, 제공 파기 및 정보 주체의 권리 등 규정 |
  | 개인정보의 안전성 확보조치 기준 | 개인정보 처리자가 개인정보를 처리함에 있어서 분실, 도난, 유출, 변조, 훼손되지 않도록 안전성을 확보하기 위해 취해야 하는 세부적인 기준 규정<br>개인정보 처리시스템의 보호 수준을 진단, 암호화에 상응하는 조치 필요 여부를 판단할 수 있는 기준을 규정 |

  > 개망신법 : 주요 3법인 개인정보보호법, 정보통신망법, 신용정보법을 현업에서 줄여서 표현
  >
  > 마이 데이터(My Data) : 개인이 자신의 정보를 관리.통제할 뿐만 아니라 이러한 정보를 신용이나 자산관리 등에 능동적으로 활용하는 일련의 과정



### 8. 다음 중 개인정보 비식별 조치 방법으로 가장 적절한 것은 무엇인가?

조치 전 : 주민등복번호 901212-1234567

조치 후 : 90년대 생, 남자

1. 가명처리 2.총계처리 3. 데이터 삭제 4. 데이터 마스킹

- 비식별 조치 방법 (아래 표)

- | 기법                                | 세부기술                                                     | 예시                                                         |
  | ----------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | 가명처리<br>(Pseudonymization)      | 휴리스틱 익명화<br>암호화<br>교환방법                        | 개인 식별이 가능한 데이터에 대하여 직접 식별할 수 없는 다른 값으로 대체하는 기법<br>예) 장길산, 20세, 인천 거주 > 김식별, 20대, 인천 거주 |
  | 총계처리<br>(Aggregation)           | 총계처리 기본 방식<br>부분 집계<br>라운딩<br>데이터 재배열   | 개인 정보에 대하여 통곗값을 적용하여 특정 개인을 판단할 수 없도록 하는 기법<br>예) 장길정 160cm, 김식별 150cm > 물리학과 학생 키 핪: 310cm, 평균키 : 155cm |
  | 데이터 삭제<br>(Data Reduction)     | 속성값 삭제<br>속성값 부분 삭제<br>준 식별자 제거를 통한 단순 익명화 | 개인정보 식별이 가능한 특정 데이터값 삭제 처리 기법<br>예) 주민번호 801212-1234567 > 80년대 생, 남자, 개인과 관련된 날짜 정보는 연 단위로 처리 |
  | 데이터 범주화<br>(Data Suppression) | 범주화 기본 방식<br>랜덤 올림 방식<br>범위 방법<br>세분 정보 제한 방법<br>제어 올림 방법 | 단인 식별 정보를 해당 그룹의 대푯값으로 변환(범주화)하거나 구간 값으로 변환(범위화)하여 고유 정보 추적 및 식별 방지 기법<br>예) 장길산, 41세 > 장 씨, 40~50세 |
  | 데이터 마스킹<br>(Data Masking)     | 임의 잡음 추가 방법<br>공백과 대체 방법                      | 개인 식별 정보에 대하여 전체 또는 부분적으로 대체값(공백, '*', 노이즈 등)으로 변환<br>예) 장길산 41세, 서울 거주, 미래대학 재학 > 장OO, 41세, 서울 거주, OO대학 재학 |

- 출생년도, 성별 외에 개인식별에 중요한 나머지 값을 삭제 하였으므로 데이터 삭제에 해당한다.

- 주민등록번호에서 연도 정보와 성별(남자) 정보만 남기고 주민등록번호는 삭제처리 한다.



### 9. 다음 중 분석 로드맵 단계로 가장 적절한 것은 무엇인가?

1. 데이터 분석체계 도입 > 데이터 분석 유효성 검증 > 데이터 분석 확산 및 고도화
2. 데이터 분석체계 도입 > 데이터 분석 확산 및 고도화 > 데이터 분석 유효성 검증 
3. 데이터 분석 유효성 검증 > 데이터 분석 확산 및 고도화 >데이터 분석체계 도입
4. 데이터 분석 유효성 검증  > 데이터 분석체계 도입 > 데이터 분석 확산 및 고도화

- 분석 로드맵은 3단계로서 데이터 분석체계 도입, 데이터 분석 유효성 검증, 데이터 분석 확산 및 고도화의 단계로 이루어 진다.



### 11. 다음 중 Fayyad가 프로파일링 기술을 기반으로 통계적 패턴이나 지식을 찾기 위해 체계적으로 정리한 방법론으로 가장 적절한 것은 무엇인가?

1. 빅데이터 분석 방법론
2. KDD 분석 방법론
3. CRISP-DM 분석 방법론
4. SEMMA 분석 방법론



- KDD 분석 방법론
  - 개념 : Knowledge Discovery in Database. 1996년 Fayyad가 프로파일링 기술을 기반으로 통계적 패턴이나 지식을 찾기 위해 체계적으로 정리한 방법론이다.
  - 방법론의 절차
    - 데이터 세트 선택(Selection)
    - 데이터 전처리 (Preprocessing)
    - 데이터 변환(Transformation)
    - 데이터 마이닝(Data Mining)
    - 데이터 마이닝 결과 평가(Interpretation / Evaluation)
- CRISP-DM 분석 방법론
  - 개념 : Cross Industry Standard Process for Data Mining. 비즈니스의 이해를 바탕으로 데이터 분석 목적의 6단계로 진행되는 데이터 마이닝 방법론
  - 분석절차 : 업무 이해 > 데이터 이해 > 데이터 준비 > 모델링 > 평가 > 전개
- SEMMA 분석 방법론
  - 개념 : Sampling Exploration Modification Modeling Assessment. 분석 솔루션 업체 SAS사가 주도한 통계 중심의 5단계(Sampling > 탐색 > 수정 > 모델링 > 검증) 방법론이다.
  - 절차 
    - 샘플링(Sampling)
    - 탐색(Exploration)
    - 수정(Modification)
    - 모델링(Modeling)
    - 검증(Assessment)



### 12. 다음 중 데이터 확보 계획 수립 절차로 가장 적절한 것은?

1. 목표 정의 > 계획 수립 > 요구사항 도출 > 예산안 수립
2. 목표 정의 > 계획 수립 > 예산안 수립 > 요구사항 도출
3. 목표 정의 > 요구사항 도출 > 예산안 수립 > 계획 수립
4. 목표 정의 > 요구사항 도출 > 계획 수립 > 예산안 수립



- 데이터 확보 계획 수립 절차는 4단계로 목표 정의, 요구사항 도출, 예산안 수립, 계획 수립으로 수행된다.

### 13. 다음 중 분석 작업 WBS 설정 중 분석목표 정의서를 기준으로 프로젝트 전체 일정에 맞게 사전 준비를 하는 단계로 가장 적절한 것은?

1. 데이터 분석과제 정의
2. 데이터 준비 및 탐색
3. 데이터 분석 모델링 및 검증
4. 산출물 정리



- 분석 작업 WBS 설정 중 분석목표 정의서를 기준으로 프로젝트 전체 일정에 맞게 사전준비를 하는 단계는 데이터 분석과제 정의 단계이다.



### 14. 다음 중 내부 데이터로 가장 부적절한 것은 무엇인가?

1. ERP 데이터   2. 방화벽 데이터   3. 고객 포털 시스템 데이터   4. SNS 데이터

- 수집 데이터 대상으로는 내부 데이터와 외부 데이터가 있다.
  - 내부 데이터 : 서비스, 네트워크, 마케팅 분야
  - 외부 데이터 : 소셜, 외부 네트워크, 공공 데이터 분야



### 17. 다음 중 데이터 정확성 품질특성 세부요소로 가장 부적절한 것은 무엇인가?

1. 사실성   2. 필수성   3. 연관성   4. 무결성

- 데이터 정확성 품질특성의 세부요소에는 정확성, 사실성, 적합성, 필수성, 연관성이 있다. (사정적필연)
- 데이터 일관성 품질특성의 세부요소에는 정합성, 일치성, 무결성이 있다. (무일정합)



### 18. 빅데이터 적재 도구로 가장 부적절한 것은 무엇인가?

1. 플루언티드    2. 플럼    3. HDFS    4. 스크라이브

- 데이터 적재 소프트웨어 아키텍처
  - 하둡, 인메모리 데이터베이스, 데이터분석 플랫폼, 데이터 시각화
- 데이터 적재 도구
  - 플루언티드(Fluentd), 플럼(Flume), 스크라이브(Scribe), 로그스태시(Logstash)
- 빅데이터 저장 기술
  - 구글 파일 시스템(GFS), 하둡분산파일시스템(HDFS), 러스터(Lustre)
- 데이터베이스 클러스터
  - Oracle RAC, IBM DB2 ICE, SQL Server, MySQL
- NoSQL
  - 구글 빅테이블, HBase, 아마존 SimpleDB, 마이크로소프트 SSDS
- 병렬DBMS
  - Volt DB , SAP HANA
- 네트워크 구성 저장 시스템
  - SAN , NAS
- 클라우드 파일 저장 시스템
  - Amazon S3, OpenStack Swift
- HDFS는 네트워크를 통해 공유하는 여러 호스트 컴퓨터의 파일에 접근할 수 있게 하는 분산 파일 시스템이다.



### 19. 다음 중 다수의 마이크로프로세서를 사용하여 여러 디스크에 대한 질의, 갱신, 입출력 등의 데이터베이스 처리를 동시에 수행하는 데이터베이스 시스템으로 가장 부적절한 것은 무엇인가?

1. Volt DB    2. SAP HANA    3. Netezza    4. HBase



- 다수의 마이크로프로세서를 사용하여 여러 디스크에 대한 질의, 갱신, 입출력 등의 데이터베이스 처리를 동시에 수행하는 데이터베이스 시스템은 병렬 DBMS이다.
- VoltDB, SAP HANA, Netezza, Vertica, Greenplum은 대표적인 병렬 DBMS이다.
- HBase 는 NoSQL 이다.

### 20. 다음 중 클라우드 파일 저장 시스템으로 가장 적절한 것은 무엇인가?

1. OpenStack Swfit    2. SAN    3. NAS    4. SAP HANA



- 클라우드 파일 저장 시스템은 클라우드 컴퓨팅 환경에서 가상화 기술을 활용한 분산 파일 시스템이다.
- OpenStack Swift는 오브젝트 스토리지로 클라우드 파일 저장 시스템으로 적절하다.
- 오브젝트 스토리지는 데이터를 오브젝트라고 불리는 개별 단위로 서버의 블록이나 폴더에 파일을 저장하는 대신 단일 저장소에 저장한다. 사용한 만큼 비용을 지불하면 되며 퍼블릭 클라우드에 적합하다.



### 21. 다음 중 실시간으로 발생하는 이벤트 처리에 대한 결과값을 수집하고 처리하는 기술은 무엇인가?

1. CEP    2. 맵리듀스    3. ETL    4. 피그

- 데이터 정제 기술
  - ETL : 추출 - 가공 - 저장
  - 맵리듀스 : (키-값) 배치처리
  - 스파크/스톰 : 인 메모리 기반
  - CEP : 실시간 이벤트 처리
  - 피그 : 대용량 데이터 집합
  - 플럼 : 로그 수집&처리
- 실시간 이벤트 처리 기술에는 CEP(Complex Event Processing)가 있다.
- IoT 센싱 데이터, 로그, 음성 데이터 등 실시간 처리가 가능하다.



### 24. 다음 중 특정 모델링 기법에 의존하지 않고 데이터의 통계적 특성으로 부터 변수를 택하는 기법으로 적절한 것은 무엇인가?

1. 필터 기법    2. 임베디드 기법    3. 라쏘    4. 릿지



- 필터 기법(Filter Method)
  - 특정 모델링 기법에 의존하지 않고 데이터의 통계적 특성으로부터 변수를 택하는 기법은 필터 기법(Filter Method)이다.
  - 필터기법은 계산 속도가 빠르고 변수 간 상관관계를 알아내는데 적합
- 래퍼 기법(Wrapper Method)
  - 가장 좋은 성능을 보이는 하위 집합을 선택하는 기법
  - 하위 집합을 반복해서 선택하여 테스트하므로, 그리디 알고리즘에 적합. 시간이 오래 걸리고, 과적합의 위험
  - 필터 방법보다 정확도가 높음
  - 종류
    - RFE(Recursive Feature Elimination) : SVM(Support Vector Machine)을 사용하여 재귀적으로 제거하는 방법
    - SFS(Sequential Feature Selection) : 그리디 알고리즘으로 특성 변수를 하나씩 추가하는 방법
    - 유전 알고리즘(Genetic Algorithm) : 자연세계의 진화과정에 기초한 계산 모델, 최적화 문제를 해결하는 기법
    - 단변량 선택(Univariate Selection) : 하나의 변수 선택법으로, 피처와 반응변수 간 관계의 강도를 결정하는 방법. 데이터에 대한 이해를 높일 때 사용
    - mRMR(Minimum Redundancy Maximum Relevance) : 특성 변수의 중복성을 최소화하는 방법으로 종속 변수를 잘 예측하면서, 독립변수들과도 중복성이 적은 변수들을 선택하는 방법
- 임베디드 기법
  - 모델의 정확도에 기여하는 변수를 학습한다.
  - 적은 계수를 가지는 회귀식을 찾는 방향으로 제약조건을 주어 이를 제거한다.
  - 기법 사례
    - 라쏘(LASSO; Least Absolute Shrinkage and Selection Operator) : 가중치의 절댓값의 합을 최소화하는 것을 추가적인 제약조건으로 하는 방법. L1-norm을 통해 제약을 주는 방법
    - 릿지(Ridge) : 가중치들의 제곱합을 최소화하는 것을 추가적인 제약조건으로 하는 방법. L2-norm을 통해 제약을 주는 방법
    - 엘라스틱 넷(Elastic Net) : 라쏘와 릿지 두 개를 선형 결합한 방법
    - SelectFromModel : 의사결정나무 기반 알고리즘에서 변수를 선택하는 방법



### 25. 다음 중 원래의 데이터 세트의 변수들을 선형 변화하여 서로 직교하도록 선택된 새로운 변수들을 생성, 이를 통해 원래 변수를 설명하고자 하는 기법으로 가장 적절한 것은 무엇인가?

1. 주성분 분석    2. 특이값 분해    3. 요인 분석    4. 다차원 척도법

- 주성분 분석(PCA; Principal Component Analysis)
  - 변수들의 공분산 행렬이나 상관행렬을 이용하고 행의 수와 열의 수가 같은 정방행렬에서만 사용한다.
  - 고차원 공간의 표본들을 선형 연관성이 없는 저차원 공간으로 변환하는 기법
  - 원래의 데이터 세트의 변수들을 선형 변환하여 서로 직교하도록 선택된 새로운 변수들(주성분)을 생성, 이를 통해 원래 변수를 설명하고자 하는 기법은 주성분 분석이다.
- 특이값 분해(SVD; Singular Value Decomposition)
  - $M$ X $N$  차원의 행렬데이터에서 특이값을 추출하고 이를 통해 주어진 데이터 세트를 효과적으로 축약할 수 있는 기법
- 요인분석(Factor Analysis)
  - 데이터 안에 관찰할 수 없는 잠재적인 변수(Latent Variable)가 존재한다고 가정
  - 모형을 세운 뒤 관찰 가능한 데이터를 이용하여 해당 잠재 요인을 도출하고 데이터 안의 구조를 해석하는 기법
  - 주로 사회과학이나 설문 조사 등에서 많이 사용
- 독립성분분석(ICA; Independent Component Analysis)
  - 주성분 분석과는 달리, 다변량의 신호를 통계적으로 독립적인 하부성분으로 분리하여 차원을 축소하는 기법
  - 독립 성분의 분포는  비정규 분포를 따르게 되는 차원축소 기법
- 다차원 척도법(MDS; Multi-Dimensional Scaling)
  - 개체들 사이의 유사성, 비유사성을 측정하여 2차원 또는 3차원 공간상에 점으로 표현하여 개체들 사이의 집단화를 시각적으로 표현하는 분석 방법



### 27. 다음 중 데이터를 0을 중심으로 양쪽으로 데이터를 분포시키는 방법으로 가장 적절한 것은 무엇인가?

1. 단순 기능 변환    2. 비닝    3. 정규화    4. 표준화



- 단순 기능 변환(Simple Functions)
  - 한쪽으로 치우친 변수를 변환하여 분석 모형을 적합하게 하는 방법
  - 예) 로그 변환($log x$), 역수 변환($1/x$), 루트 변환($$ \sqrt{x}$$ ), 제곱 변환($x$<sup>2</sup>)
- 비닝(Binning)
  - 기존 데이터를 범주화하기 위해 사용
  - Categorization 기술의 결정은 비즈니스 도메인 지식 필요
  - 두 개 이상 변수의 값에 따라 공변량 비닝(co-variate binning) 수행
  - 예) 수입을 상, 중, 하의 범주로 나누기
- 정규화(Normalization)
  - 데이터를 특정 구간으로 바꾸는 척도법
  - 최소-최대 정규화, Z-스코어 정규화 유형이 있음
  - ![min-max-normal](https://user-images.githubusercontent.com/291782/132291835-9ddef979-be73-4178-ab89-4459fae32484.png)
- 표준화(Standardization)
  - 데이터를 0을 중심으로 양쪽으로 데이터를 분포시키는 방법
  - 표준화와 정규화는 데이터 전처리에서 상호 교환하여 사용
  - ![Z-score](https://user-images.githubusercontent.com/291782/132292070-0d80dac0-29cc-4b49-9d7e-3b45b55bf22b.png)





### 29. 다음 중 개별 변수 탐색 방법 중 가장 적절하지 않은 것은?

1. 범주형 데이터의 시각화는 히스토그램을 이용한다.
2. 범주형 데이터는 빈도수, 최빈값, 비율, 백분율 등을 이용하여 데이터의 분포 특성을 중심성, 변동성 측면에서 파악한다.
3. 수치형 데이터는 평균, 분산, 표준 편차, 첨도, 왜도 등을 이용하여 데이터의 분포 특성을 중심성, 변동성, 정규성 측면에서 파악한다.
4. 수치형 데이터는 등간 척도와 비율 척도로 탐색한다.



- 수치형 데이터 시각화는 박스 플롯이나 히스토그램을 주료 이용
- 범주형 데이터의 시각화는 막대형 그래프를 주로 이용한다.



### 34. 다음 일변량 데이터 탐색 방법으로 가장 알맞은 것은 무엇인가?

1. 기술 통계량    2. 산점도 행렬    3. 별 그림    4. 등고선 그림

- 일변량 데이터 탐색 방법에는 기술 통계량, 그래프 통계량 두 가지 종류가 있다.
  - 기술 통계량에는 평균, 분산, 표준편차 등이 있다.
  - 그래프 통계량에는 히스토그램, 상자 그림 등이 있다.
- 이변량 데이터 탐색
  - 조사 대상의 각 개체로부터 두 개의 특성을 동시에 관측함
  - 일반적으로 두 변수 사이의 관계를 밝히려는 것이 관심의 대상임
- 다변량 데이터 탐색 도구로는 산점도 행렬, 별 그림, 등고선 그림이 있다.



### 36. 다음 중 회귀 분석에서 독립변수 선택 방법으로 가장 부적절한 것은 무엇인가?

1. 후진 제거법    2. 전진 선택법    3. ANOVA    4. 단계적 방법

- 회귀 분석에서 독립변수 선택 방법으로는 후진 제거법, 전진 선택법, 단계적 방법이 있다.
- 분산 분석(ANOVA; Analysis of Variance)은 두 개 이상의 집단 간 비교를 수행하고자 할 때 집단 내의 분산, 총 평균과 각 집단의 평균 차이에 의해 생긴 집단 간 분산 비교로 얻은 F-분포를 이용하여 가설검정을 수행하는 방법



### 37. 다음 중 서열과 의미 있는 차이를 가지는 척도로 가장 알맞은 것은?

1. 명목 척도    2. 구간 척도    3. 순서 척도    4. 비율 척도

- 척도

- | 속성      | 척도                          | 설명                                                         | 예시                     |
  | --------- | ----------------------------- | ------------------------------------------------------------ | ------------------------ |
  | 질적 속성 | 명목 척도<br>(Norminal Scale) | 단순히 집단의 분류를 목적으로 사용된 척도<br>등호 연산(=, !=) | 이메일 주소,옷색깔, 성별 |
  | 질적 속성 | 순서 척도<br>(Ordinal Scale)  | 측정대상 사이의 대소 관계를 나타내기 위한 척도<br>비교 연산(< , > ) | 직급, 영화 평점, 선호도  |
  | 양적 속성 | 구간 척도<br>(Interval Scale) | 등간 척도라고도 하며 서열과 의미 있는 차이를 가지는 척도     | 온도, 지능지수           |
  | 양적 속성 | 비율 척도<br>(Ratio Scale)    | 구간 척도의 성질을 가지면서도 척도 간의 비(ratio)도 의미가 있는 척도<br>승제 연산(X, %) | 질량, 나이, 개수, 길이   |

  



### 39. 다음 중 모집단의 특성을 나타내는 대푯값으로 가장 알맞은 것은 무엇인가?

1. 모집단    2. 표본 표준편차    3. 통계량    4. 모수

- 모집단(Population) : 정보를 얻고자 하는 대상이 되는 집단 전체
- 모수(Parameter) : 모집단의 특성을 나타내는 대푯값이다.
- 통계량(Statistic) : 표본에서 얻은 평균이나 표준 오차와 같은 값. 이 값을 통해 모수를 추정하며, 무작위로 추출할 경우 각 표본에 따라 달라지는 확률변수
- 추정량(Estimator) : 모수의 추정을 위해 구해진 통계량
- 표준편차(Standard Deviation) : 자료의 변동 정도, &sigma; , $s$ 를 의미
- 표준오차(Standard Error) : 통계량의 변동 정도를 의미. 평균을 낸 값들의 표준편차를 오차라고 부름. &sigma;<sub>x</sub> , $s$<sub>x</sub>로 표기(보통은 X위에 Bar가 있는 형태로 표기)



### 40. 다음 중 점 추정 조건으로 가장 부적절한 것은 무엇인가?

1. 불편성    2. 효율성    3. 일치성    4. 기능성

- 점 추정 개념 : 표본의 정보로부터 모집단의 모수를 하나의 값으로 추정하는 기법. 표본의 평균, 중위수, 최빈값 등을 사용
- 점 추정 조건으로는 불편성, 효율성, 일치성, 충족성이 있다.
  - 불편성(Unbiasedness) : 모든 가능한 표본에서 얻은 추정량의 기댓값은 모집단의 모수와 차이가 없음
  - 효율성(Efficiency) : 추정량의 분산이 작을수록 좋음
  - 일치성(Consistency) : 표본의 크기가 아주 커지면, 추정량이 모수와 거의 같아짐
  - 충족성(Sufficient) : 추정량은 모수에 대하여 모든 정보를 제공
- 점 추정에 사용되는 통계 : 표본평균, 표본분산, 중위수, 최빈값이 있다.




### 41. 독립변수와 종속변수 모두 연속형일 경우 사용 가능한 기법으로 가장 알맞지 않은 것은?

1. 회귀 분석    2. 인공신경망 모델    3. K-최근접이웃기법    4. 로지스틱 회귀 분석



- 독립변수와 종속변수가 주어진 경우 분석기법(아래 표)

- |             |             | 종속변수(Y)                                       | 종속변수(Y)                                  |
  | ----------- | ----------- | ------------------------------------------------- | -------------------------------------------- |
  |             |             | 연속형                                            | 범주형                                       |
  | 독립변수(X) | 연속형 변수 | 회귀분석, 인공신경망 모델,KNN                     | 로지스틱 회귀분석, 판별 분석, KNN            |
  | 독립변수(X) | 범주형 변수 | 회귀분석, 인공신경망 모델, 의사결정나무(회귀나무) | 인공신경망 모델, 분류나무, 로지스틱 회귀분석 |

- 로지스틱 회귀 분석은 종속변수가 범주형일 경우 사용 가능한 기법이다.

- 독립 변수만 주어진 경우 분석 기법
  - 연속형 변수 : 주성분 분석, 군집 분석, 상관 분석
  - 범주형 변수 : 연관성 규칙, 판별 분석, 상관 분석
- ![2var-anal](https://user-images.githubusercontent.com/291782/132309562-1faf3422-252d-4fa0-bc16-59626ec9a176.png)



### 43. 다음 중 분석 모형 구축 절차 중 요건 정의에 따라 상세 분석기법을 적용해 모델을 개발하는 과정으로 가장 적합한 것은 무엇인가?

1. 요건 정의    2. 모델링    3. 적용    4. 검증 및 테스트

- 요건 정의는 기획단계의 분석 과제 정의를 통해 도출된 내용을 구체화하는 과정이다.
- 검증 및 테스트는 분석용 데이터를 학습용과 테스트용으로 분리한 다음 분석용 데이터를 이용해 자체 검증 후 실제 테스트에서는 신규 데이터 모델을 적용해 결과를 도출하는 단계이다.
- 적용은 분석결과를 업무 프로세스에 완전히 통합해 실제 일, 주, 월 단위로 운영하는 단계이다.
- 요건 정의에 따라 상세 분석기법을 적용해 모델을 개발하는 과정은 모델링이다.



### 46. 다음 중 다중 회귀 모형의 수식으로 가장 알맞은 것은?

1. Y = B<sub>0</sub> + B<sub>1</sub>X + &epsilon;
2. Y = B<sub>0</sub> + B<sub>1</sub>X<sub>1</sub> + B<sub>2</sub>X<sub>2</sub> + ...  + B<sub>k</sub>X<sub>k</sub> + &epsilon;
3. Y = &alpha;$e$<sup>-BX</sup> + &epsilon;
4. Y = B<sub>0</sub> + B<sub>1</sub>X<sup>1</sup> + B<sub>2</sub>X<sup>2</sup> + &epsilon;

- 회귀식
- ![regression](https://user-images.githubusercontent.com/291782/132313162-552ee002-1db4-4c68-afb4-a91f6ef2c445.png)




### 47. 다음 중 로지스틱 회귀 분석 유형을 설명한 것으로 가장 알맞지 않은 것은?

1. 반응변수가 범주형인 경우 적용되는 회귀 분석 모형이다
2. 새로운 설명변수의 값이 주어질 때 반응변수의 각 범주에 속할 확률이 얼마인지를 추정하여 추적 확률을 기준치에 따라 분류하는 목적으로 사용될 수 있다.
3. 승산비는 $$\dfrac {1-p}{p} $$로 계산한다. ( (1 - p) / p ) 
4. R을 사용하여 로지스틱 회귀 분석을 수행하고 결과를 해석할 수 있다.



- 승산(odds) : 실패에 비해 성공할 확률의 비를 의미
- 승산비는 교차비, 대응위험이라고도 하며 odds = $$\dfrac {p}{1-p}$$로 계산한다.
- 예) 게임에서 이길 확률 1/5, 질 확률이 4/5이면, odds는 1/4 이다. 계산된 값은 '5번 중에, 4번 질동안 1번 이긴다.'라고 해석한다. odds = p/(1-p) = $$ \dfrac { \dfrac {1}{5}}{\dfrac {4}{5}} $$  = 1/4



### 50. 다음 중 서포트 벡터 머신의 구성요소로 가장 알맞지 않은 것은?

1. 초평면    2. 활성화 함수    3. 서포트 벡터    4. 슬랙 변수

- 서포트 벡터 머신은 초평면 중에서 데이터들과 거리가 가장 먼 초평면을 선택하여 분리하는 지도학습 기반의 이진 선형 분류 모델이다.
- 기계학습의 한 분야로 사물 인식, 패턴 인식, 손 글씨 숫자 인식 등 다양한 분야에서 활용되고 있는 지도 학습 모델
- 서포트 벡터 머신의 구성요소 : 결정 경계, 초평면, 마진, 서포트 벡터, 슬랙 변수 (결초마서슬)
- ![svm-factor](https://user-images.githubusercontent.com/291782/132357686-6e51e806-6b55-4821-9a00-bd220fbd74eb.png)
- SVM 구성 요소
    - 결정 경계(Decision Boundary) : 데이터 분류의 기준이 되는 경계
    - 초평면(Hyperplane) : n 차원의 공간의 (n-1)차원 평면
    - 마진(Margin) : 결정 경계에서 서포트 벡터까지의 거리(즉, 여유 공간)
    - 서포트 벡터(Support Vector) : 학습 데이터 중에서 결정 경계와 가장 가까이 있는 데이터 들의 집합
    - 슬랙 변수(Slack Variable 또는 여유 변수) : 완벽한 분리가 불가능할 때 선형적으로 분류를 위해 허용된 오차를 위한 변수. Soft Margin SVM에서 사용
- 활성화 함수는 인공신경망에서 순 입력함수로 부터 전달받은 값을 출력값으로 변환해 주는 함수이다.



### 52. 다음 중 아래 그림과 같이 군집 내의 오차 제곱합(Error Sum of Square)에 기초하여 군집을 수행하는 기법은 무엇인가?

![error-sum-of-square](https://user-images.githubusercontent.com/291782/132358573-dc9236db-d135-4c09-bc33-1ef8c705fff6.png)

1. 최장 연결법    2. 중심 연결법    3. 평균 연결법    4. 와드 연결법

- 최단연결법 : 두 군집 사이의 거리를 각 군집에서 하나씩 관측값을 뽑았을 때 나타날 수 있는 거리의 최솟값으로 측정
- 최장연결법 : 두 군집 사이의 거리를 각 군집에서 하나씩 관측값을 뽑았을 때 나타날 수 있는 거리의 최댓값으로 측정
- 중심연결볍 : 두 군집이 결합될 때 새로운 군집의 평균은 가중 평균을 통해 구함
- 평균연결법 : 모든 항목에 대한 거리 평균을 구하면서 군집화
- 와드연결법 : 군집 내의 오차 제곱합(Error Sum of Square)에 기초하여 군집을 수행하는 기법



### 53. 독립변수, 종속변수, 분석 방법의 짝지어진 것 중 가장 적절하지 않은 것은 무엇인가?

1. 독립변수(범주형) - 종속변수(범주형) - 분석방법(분할표 작성)
2. 독립변수(범주형) - 종속변수(범주형) - 분석방법(교차분석)
3. 독립변수(수치형) - 종속변수(수치형) - 분석방법(피셔의 정확 검정)
4. 독립변수(수치형) - 종속변수(범주형) - 분석방법(로지스틱 회귀 분석)

- | 독립변수 | 종속변수 | 분석 방법                                              |
    | -------- | -------- | ------------------------------------------------------ |
    | 범주형   | 범주형   | 분할표 분석, 교차분석(카이제곱 검정), 피셔의 정확 검정 |
    | 수치형   | 범주형   | 로지스틱 회귀 분석                                     |

- 피셔의 정확 검정은 독립변수와 종속변수 모두 범주형인 경우이다.





> 정상성의 조건 : 평균이 일정하다. 분산이 시점에 의존하지 않는다. 공분산은 단지 시차에만 의존하고 시점 자체에는 의존하지 않는다.



### 57. 딥러닝 알고리즘 종류

- DNN(Deep Neural Network) : 은닉층을 심층(Deep) 구성하여 입력층에서 부터 은닉층, 출력층으로 이동하고 역전파 알고리즘을 수행하는 심층신경망
- CNN(Convolution NN) : 기존 영상처리의 필터 기능(Convolution)과 신경망(Neural Network)을 결합하여 성능을 발휘하도록 만든 구조의 합성곱 신경망
- RNN(Recurrent NN) : 입력층에서 전달받은 순차적인 데이터를 은닉층으로 전달하며 재귀적 구조의 순환 신경망
- GAN(Generative Adversarial Network) : 가짜 데이터를 생성하는 생성 모델과 데이터를 진짜와 가짜로 분류하는 분류 모델로 구성된 생성적 적대 신경망



### 59. 다음 의사결정나무의 특징인 분산이 크다는 점을 고려하여 더 많은 무작위성을 주어 약한 학습기들을 생성한 후 이를 선형 결합하여 최종 학습기를 만드는 방법으로 가장 알맞은 것은?

1. 배깅(Bagging)    2. 부스팅(Boosting)    3. 랜덤 포레스트(Random Forest)    4. 보팅(Voting)

- 배깅 : 학습 데이터에서 다수의 부트스트랩(Bootstrap) 자료를 생성하고, 각 자료를 모델링 한 후 결합하여 최종 예측 모형을 만드는 알고리즘이다.
- 부스팅: 잘못 분류된 개체들에 가중치를 적용, 새로운 분류 규칙을 만들고, 이 과정을 반복해 최종 모형을 만드는 알고리즘이다.
- 보팅 : 여러개의 머신러닝 알고리즘 모델을 학습시킨 후 새로운 데이터에 대해 각 모델의 예측값을 가지고 다수결 투표를 통해 최종 클래스를 예측하는 기법이다.
- 랜덤포레스트 : 더 많은 무작위성을 주어 약한 학습기들을 생성한 후 이를 선형 결합하여 최종학습기를 만드는 알고리즘



### 60. 다음 중 비모수 통계량으로 가장 부적절한 것은 무엇인가?

1. 빈도    2. 부호    3. 표준편차    4. 순위

- 모수 통계량에는 평균, 분산, 표준편차가 있다.


