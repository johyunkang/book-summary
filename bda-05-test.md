## 빅분기 최종모의고사 1회

### 03. 경영 전략, 사업 전략, 서비스 전략을 수행할 수 있도록 전체 조직의 수준에서 조직의 구조를 설계하여야 한다. 다음 설명 중 기능 조직 구조를 가장 바르게 설명한 것은?

1. 전사 분석 업무를 별도의 분석 전담 조직에서 담당한다.
2. 일반적인 형태로 별도 분석조직이 없고 해당 부서에서 분석을 수행한다.
3. 전사적 핵심 분석이 가능하며 진취적인 분석 수행이 가능하다.
4. 분석조직 인력들을 현업 부서로 직접 배치하여 분석 업무를 수행한다.

- 기능 조직에서는 별도 분석 조직이 없고 해당 부서에서 분석을 수행한다.
- 전사적 핵심 분석이 어려우며 과거에 국한된 분석을 수행한다.
- 2번



### 04. 다음 중 데이터 사이언티스트에게 요구되는 역량을 설명한 것으로 가장 부적절한 것은 무엇인가?

1. 스토리텔링, 데이터 시각화를 사용한 등 설득력 있는 전달을 위해 소프트 스킬이 필요하다.
2. 빅데이터에 대한 이론적 지신인 소프트 스킬이 필요하다.
3. 최적의 분석 설계 및 노하우 축적하는 등 분석기술에 대한 숙련을 위해 하드 스킬이 필요하다.
4. 창의적 사고, 호기심, 논리적 비판하는 소프트 스킬이 필요하다.



- 데이터 사이언티스트는 빅데이터에 대한 이론적 지식인 하드스킬이 필요하다.
- 2번



### 06. 빅데이터 플랫폼은 원천 데이터에서 정형, 반정형, 비정형 데이터를 수집하고 저장한다. 다음 중 빅데이터 수집 기술로 가장 부적절한 기법은 무엇인가?

1. No SQL
2. ETL
3. EAI
4. 크롤러(Crawler)



- 빅데이터 플랫폼은 크게 수집, 저장, 분석, 활용 단계로 구성됨
- NoSQL은 저장 기술이다.



### 10. 하둡 에코시스템(Hadoop Ecosystem)

하둡 프레임워크를 이루고 있는 다양한 서브 프로젝트들의 모임

하둡 에코시스템 수집, 저장, 처리 기술

- 비정형 데이터 수집
  - 척와(Chukwa) : 분산된 각 서버에서 에이전트를 실행하고, 컬렉터(Collector)가 에이전트로부터 데이터를 받아 HDFS에 저장
  - 플럼(Flume) : 많은 양의 로그 데이터를 효율적으로 수집, 집계, 이동하기 위해 이벤트와 에이전트(Agent)를 활용하는 기술
  - 스크라이브(Scribe)
    - 다수의 서버로부터 실시간으로 스트리밍되는 로그 데이터를 수집하여 분산 시스템에 데이터를 저장하는 대용량 실시간 로그 수집 기술
    - 최종 데이터는 HDFS 외에 다양한 저장소를 활용 가능
    - HDFS에 저장하기 위해서는 JNI(Java Native Interface)를 이용
- 정형 데이터 수집
  - 스쿱(Sqoop)
    - 대용량 데이터 전송 솔루션
    - 커넥터를 사용하여 RDBMS에서 HDFS로 데이터를 수집하거나, HDFS에서 RDBMS로 데이터를 보내는 기능 수행
    - Oracle, MS-SQL, DB2와 같은 상용 RDBMS와 MySQL과 같은 오픈소스 RDBMS 지원
  - 히호(Hiho)
    - 스쿱과 같은 대용량 데이터 전송 솔루션이며, 현재 깃허브에서 공개되어 있음
    - 하둡에서 데이터를 가져오기 위한 SQL을 지정할 수 있으며, JDBC 인터페이스를 지원, 현재는 Oracle, MySQL의 데이터만 전송 지원
- 분산 데이터 저장
  - HDFS
    - 대용량 파일을 분산된 서버에 저장하고, 그 저장된 데이터를 빠르게 처리할 수 있게 하는 하둡 분산 파일 시스템
    - 범용 하드웨어 기반, 클러스터에서 실행되고 데이터 접근 패턴을 스트리밍 방식으로 지원
    - 다중 복제, 대량 파일 저장, 온라인 변경, 범용서버 기반, 자동복구 특징이 있음
- 분산 데이터 처리
  - 맵리듀스(Map Reduce)
    - 대용량 데이터 세트를 분산 병렬 컴퓨팅에서 처리하거나 생성하기 위한 목적으로 만들어진 소프트웨어 프레임워크
    - 모든 데이터를 Key - Value 쌍으로 구성, 데이터를 분류
- 분산 데이터 베이스
  - HBase
    - 컬럼 기반 저장소로 HDFS와 인터페이스 제공
    - 실시간 랜덤 조회 및 업데이트를 할 수 있으며, 각각의 프로세스는 개인의 데이터를 비동기적으로 업데이트할 수 있음



하둡 에코시스템의 데이터 가공 및 분석, 관리를 위한 주요 기술

- 데이터 가공
  - 피그(Pig)
    - 대용량 데이터 집합을 분석하기 위한 플랫폼으로 하둡을 이용하여 맵리듀스를 사용하기 위한 높은 수준의 스크립트 언어인 **피그 라틴**이라는 자체 언어를 제공
    - 맵리듀스 API를 매우 단순화시키고, SQL과 유사한 형태로 설계됨
    - SQL과 유사하기만 할 뿐, 기존 SQL 지식을 활용하는 것이 어려움
  - 하이브(Hive)
    - 하둡 기반의 DW(Data Warehouse) 솔루션
    - SQL과 매우 유사한 HiveQL이라는 쿼리를 제공
    - HiveQL은 내부적으로 맵리듀스로 변환되어 실행됨
- 데이터 마이닝
  - 머하웃(Mahout)
    - 하둡 기반으로 데이터 마이닝 알고리즘을 구현한 오픈소스
    - 분류, 클러스터링, 추천 및 협업 필터링, 패턴 마이닝, 회귀 분석, 진화 알고리즘 등 주요 알고리즘 지원
- 실시간 SQL 질의
  - 임팔라(Impala)
    - 하둡 기반의 실시간 SQL 질의 시스템
    - 데이터 조회를 위한 인터페이스로 HiveQL을 사용
    - 수초 내에 SQL 질의 결과를 확인할 수 있으며, HBase와 연동이 가능
- 워크플로우 관리
  - 우지(Oozie)
    - 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템
    - 자바 서블릿 컨테이너에서 실행되는 자바 웹 애플리케이션 서버
    - 맵리듀스나 피그와 같은 특화된 액션들로 구성된 워크플로우 제어
- 분산 코디네이션
  - 주키퍼(Zookeeper)
    - 분산 환경에서 서버들 간에 상호 조정이 필요한 다양한 서비스를 제공
    - 하나의 서버에만 서비스가 집중되지 않도록 서비스를 알맞게 분산하여 동시에 처리
    - 하나의 서버에서 처리한 결과를 다른 서버들과도 동기화하여 데이터의 안정성을 보장



### 12. 다음 중 개인정보 비식별 조치 방법으로 가장 올바르게 설명한 것은 무엇인가?

1. 데이터 마스킹: 정약용, 21세 > 박씨, 20~30세
2. 데이터 범주화: 정약용, 21세 > 정씨, 평균 20세
3. 가명처리: 정약용, 21세 > 장길산, 20대
4. 총계처리: 장길산 160cm, 정약용 180cm > 학생키 150~200cm



###### 개인정보 비식별 조치 방법

| 기법                                | 세부기술                                                     | 예시                                                         |
| ----------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 가명처리<br>(Pseudonymization)      | 휴리스틱 익명화<br>암호화<br>교환방법                        | 개인 식별이 가능한 데이터에 대하여 직접 식별할 수 없는 다른 값으로 대체하는 기법<br>예) 장길산, 20세, 인천 거주 > 김식별, 20대, 인천 거주 |
| 총계처리<br>(Aggregation)           | 총계처리 기본 방식<br>부분 집계<br>라운딩<br>데이터 재배열   | 개인 정보에 대하여 통곗값을 적용하여 특정 개인을 판단할 수 없도록 하는 기법<br>예) 장길정 160cm, 김식별 150cm > 물리학과 학생 키 핪: 310cm, 평균키 : 155cm |
| 데이터 삭제<br>(Data Reduction)     | 속성값 삭제<br>속성값 부분 삭제<br>준 식별자 제거를 통한 단순 익명화 | 개인정보 식별이 가능한 특정 데이터값 삭제 처리 기법<br>예) 주민번호 801212-1234567 > 80년대 생, 남자, 개인과 관련된 날짜 정보는 연 단위로 처리 |
| 데이터 범주화<br>(Data Suppression) | 범주화 기본 방식<br>랜덤 올림 방식<br>범위 방법<br>세분 정보 제한 방법<br>제어 올림 방법 | 단인 식별 정보를 해당 그룹의 대푯값으로 변환(범주화)하거나 구간 값으로 변환(범위화)하여 고유 정보 추적 및 식별 방지 기법<br>예) 장길산, 41세 > 장 씨, 40~50세 |
| 데이터 마스킹<br>(Data Masking)     | 임의 잡음 추가 방법<br>공백과 대체 방법                      | 개인 식별 정보에 대하여 전체 또는 부분적으로 대체값(공백, '*', 노이즈 등)으로 변환<br>예) 장길산 41세, 서울 거주, 미래대학 재학 > 장OO, 41세, 서울 거주, OO대학 재학 |

- 3번


### 14. 다음 중 분석의 대상이 무엇인지를 인지하고 있는 경우(Known), 즉 해결해야 할 문제를 알고 있고 이미 분석의 방법도 알고 있는 경우(Known)에 사용하는 분석 유형은 무엇인가?

1. 최적화(Optimization), 2.솔루션(Solution), 3.통찰(Insight), 4.발견(Discovery)



- 분석 대상과 방법을 모두 알고 있는 경우(Known)에는 최적화 기법을 사용한다.
- 1



### 20. 다음 중 데이터 속성에 대한 측정 척도를 설명한 것으로 가장 부적절한 것은 무엇인가?

1. 균등 간격에 절대 영점이 없고, 비율 계산이 가능한 척도는 비율 척도이다.
2. 비계량적인 변수를 관측하기 위하여 여러 관측 대상을 적당한 기준에 따라 상대적인 비교 및 순위화를 통해 관측하는 방법은 서열 척도이다.
3. 동일 간격화로 크기 간의 차이를 비교할 수 있게 만든 척도는 등간 척도이다.
4. 관측 대상을 범주로 나눈어 분류한 후 이에 따라 기호나 숫자를 부여하는 방법은 명목 척도이다.



- 비율 척도는 균등 간격에 절대 영점이 있고, 비율 계산이 가능하다.
- 가장 전형적인 양적 변수로 쓰인다.
- 1



### 21. 다음 중 객체를 하나의 소집단으로 간주하고 단계적으로 유사한 소집단들을 합쳐 새로운 소집단을 구성해가는 데이터 세분화 기법은 무엇인가?

1. 응집분석법, 2. 분할분석법, 3.인공신경망 모델, 4.K-평균 군집화



- 응집분석법은 계층적 방법으로 각 객체를 하나의 소집단으로 간주하고 단계적으로 유사한 소집단들을 합쳐 새로운 소집단을 구성해가는 데이터 세분화 기법이다.

- 데이터 세분화 방법 상세

  |      구분      |      기법       | 설명                                                         |
  | :------------: | :-------------: | ------------------------------------------------------------ |
  |   계층적방법   |   응집분석법    | 각 객체를 하나의 소집단으로 간주하고 단계적으로 유사한 소집단들을 합쳐 새로운 소집단을 구성해 가는 기법 |
  |   계층적방법   |   분할분석법    | 전체 집단으로 부터 시작하여 유사성이 떨어지는 객체들을 분리해 가는 기법 |
  | 비 계층적 방법 | 인공신경망 모델 | 기계 학습에서 생물학의 신경망으로 부터 영감을 얻은 통계학적 학습모델 |
  | 비 계층적 방법 |  K-평균 군집화  | K개 소집단의 중심좌표를 이용하여 각 객체와 중심좌표 간의 거리를 산출하고, 가장 근접한 소집단에 배정한 후 해당 소집단의 중심좌표를 업데이트 하는 방식으로 군집화 하는 방식 |

- 1





### 22. 데이터 결측값 처리 방법에서 단순 확률 대치법이란 평균 대치법에서 관측된 자료를 토대로 추정된 통계량으로 결측값을 대치할 때 어떤 적절한 확률값을 부여한 후 대치하는 방법이다. 다음 중 단순 확률 대치법의 유형으로 가장 적절한 것은 무엇인가?

1. 평균 대치법, 2.핫덱(Hot-Deck) 대체, 3.완전 분석법, 4.다중 대치법



- 단순 확률 대치법에는 핫덱(Hot-Deck) 대체, 콜드덱(Cold-Deck)대체, 혼합방법이 있다

- 핫덱 대체는 무응답을 현재 진행 중인 연구소에서 "비슷한 성향"을 가진 응답자의 자료로 대체하는 방법이며 표본조사에서 주로 사용되는 기법이다.

- ###### 데이터 결측값 처리 방법

  - 단순 대치법

    1. 완전 분석법(Completes Analysis)

    2. 평균 대치법(Mean Imputation)

    3. 단순 확률 대치법(Single Stochastic Imputation)
       1. 핫덱(Hot-Deck) 대체 : 비슷한 성향을 가진 응답자의 자료로 대체. 표본조사에 흔히 사용
       2. 콜드덱(Cold-Deck) 대체 : 핫덱과 비슷하나 대체 자료를 현재 진행 중인 연구에서 얻는것이 아니라 외부 출처 또는 이전의 비슷한 연구에서 가져오는 방법
       3. 혼합 방법 : 몇 가지 다른 방법을 혼합하는 방법

  - 다중 대치법

    - 적용방식 : 대치 > 분석 > 결합

- 2


### 25. 다음 중 변수를 변환하는 방법을 설명한 것으로 가장 부적절한 것은 무엇인가?

1. 변수의 분포를 변경하기 위해서 로그 변환 기법을 사용한다.
2. 기존 데이터를 범주화하기 위해서 비닝(Bining) 기법을 사용한다.
3. 데이터를 특정 구간으로 바꾸는 정규화 기법을 사용한다.
4. 무작위로 정상 데이터의 일부만 선택하는 언더 샘플링 기법을 사용한다.



- 변수 변환 방법
  - 단순 기능 변환(Simple Function)
    - 한 쪽으로 치우친 변수를 변환하여 분석 모형을 적합하게 하는 방법
    - 예) 로그변환($\log$$x$), 역수 변환(1/x), 루트변환($\sqrt x$), 제곱 변환($x$^2^)
  - 비닝(Binning)
    - 기존 데이터를 범주화하기 위해 사용
    - 두 개 이상의 변수의 값에 따라 공변량 비닝(co-variate binning) 수행
    - 예) 수입을 상,중,하의 범주로 나누기
  - 정규화(Normalization)
    - 데이터를 특정 구간으로 바꾸는 척도법
    - 최소-최대 정규화, Z-스코어 정규화 유형이 있음
    - 예) 최소-최대 정규화 $x - x~min~ \over x~max~ - x~min~$
  - 표준화
    - 데이터를 0을 중심으로 양쪽으로 데이터를 분포시키는 방법
    - 표준화와 정규화는 데이터 전처리에서 상호 교환하여 사용
    - 예) Z-스코어 정규화 : Z = $x - X \over s$   : X: 평균, s: 표준편차
- 불균형 데이터 처리 기법
  - 언더 샘플링(Under-Sampling)
    - 다수 클래스의 데이터를 일부만 선택하여 데이터의 비율을 맞추는 방법
    - 데이터의 소실이 매우 크고, 중요한 정상 데이터를 잃을 수 있다.
    - 대표 기법에는 랜덤 언더 샘플링, ENN(Edited Nearest Neighbours), 토멕 링크 방법(Tomek Link Method), CNN(Condensed Nearest Neighbor), OSS(One Sided Selection) 등이 있다.
  - 오버 샘플링(Over-Sampling)
    - 소스 클래스의 데이터를 복제 또는 생성하여 데이터의 비율을 맞추는 방법으로 과대 샘플링이라고도 한다.
    - 과적합(Over-fitting)을 초래할 수 있다.
    - 알고리즘의 성능은 높으나 검증의 성능은 나빠질 수 있다.
    - 대표적인 기법에느 랜덤 오버 샘플링, SMOTE(Synthetic Minority Over-sampling TEchnique), Borderline-SMOTE, ADASYN(ADAptive SYNthetic) 등이 있다.
  - 임곗값 이동(Threshold-Moving)
    - 임곗값을 데이터가 많은 쪽으로 이동시키는 방법
    - 학습 단계에서는 변화 없이 학습하고 테스트 단계에서 임곗값을 이동한다.
    - 예) 양성 90개, 음성 10개 데이터 샘플이 있다.
      - 언더 샘플링 : 양성 클래스의 샘플을 10개로 만들기
      - 오버 샘플링 : 음성 클래스의 샘플을 90개로 만들기
      - 임곗값 이동 : 분류 시행할 때 사용되는 임곗값을 양성과 음성의 비율로 조정
  - 앙상블 기법(Ensemble Technique)
    - 앙상블은 같거나 서로 다른 여러 가지 모형들의 예측/분류 결과를 종합하여 최종적인 의사결정에 활용하는 기법
    - 오버 샘플링, 언더 샘플링, 임곗값 이동을 조합한 앙상블을 만들 수 있다.
    - 앙상블의 예측 중에서 가장 많은 표를 받은 클래스를 최종적으로 선택한다.
- 무작위로 정상 데이터의 일부만 선택하는 언더 샘플링 기법은 변수를 변환하는 방법이 아니고 불균형 데이터 처리기법이다.
- 4



### 27. 다음 중 두 변수가 키와 몸무게, 수입과 지출 등과 같은 수치적 데이터일 경우에 두 변수 사이의 연관성을 계량적으로 산출하여 분석하는 방법으로 가장 적절한 것은 무엇인가?

1. 피어슨 상관계수, 2.카이제곱 검정, 3.인공신경망 모델, 4.K-평균 군집화

- 다차원 데이터 탐색 방법
  - 범주형 - 범주형
    - 비율, 백분율 분석 등을 활용하여 데이터 간의 연관성을 분석
    - 시각화는 막대형 그래프(Bar Plot)을 주로 이용
  - 수치형 - 수치형
    - 산점도와 기울기를 통하여 변수 간의 상관성을 분석
    - 산점도를 이용하여 시각화
    - 공분산을 통하여 방향성 파악
    - 피어슨(Pearson) 상관계수를 통하여 방향성과 강도 파악
  - 범주형 - 수치형
    - 범주형 데이터의 항목들을 그룹으로 간주하고 각 그룹에 따라 수치형 변수의 기술 통계량 차이를 상호 비교
    - 그룹 간 비교를 위하여 주로 박스 플롯을 이용하여 시각화
- 수치적 데이터의 상관분석에서 피어슨 상관계수 방법을 일반적으로 사용
- 두 변수의 분산이 동일하다는 전제조건 아래에서 사용한다.
- 1



### 28. 다음 중 데이터를 탐색하기 위한 시각화 기법을 설명한 것으로 가장 부적절한 기법은 무엇인가?

1. 자료 분포의 형태를 직사각형 형태로 보여주기 위해 히스토그램을 사용한다.
2. 많은 데이터를 그림을 이용하여 집합의 범위와 중앙값을 빠르게 확인할 수 있으며, 또한 통계적으로 이상값이 있는지 빠르게 확인하기 위해 박스 플롯을 사용한다.
3. 데이터값이 큰 지역의 면적을 시각적으로 더 크게 표시하여 데이터를 직관적으로 보기 위해 버블 플롯맵을 사용한다.
4. 가로축과 세로축의 좌표평면상에서 각각의 관찰점들을 표시하여 2개의 연속형 변수 간의 관계를 보기 위하여 산점도를 사용한다.



- 데이터값이 큰 지역의 면적을 시각적으로 더 크게 표시하여 데이터를 직관적으로 보기 위해 사용하는 기법은 카토그램이다.
- 시공간 데이터 탐색에서 버블 플롯맵은 위도와 경도를 사용하여 좌표를 원으로 정의하는 차트이다.
- 3



### 30. 수치적 데이터 변수로 이루어진 두 변수 간의 선형적 연관성을 계량적으로 파악하기 위한 통계적 기법이며 일반적으로 선형적인 관계 정도를 측정하는 척도로 사용하는 기법은 무엇인가?

1. 주성분 분석 2. 스피어만 상관계수 3. 피어슨 상관계수 4. 로지스틱 회귀 분석



- 주성분 분석(PCA; Principal Component Analysis) 개념

  많은 변수의 분산방식(분산.공분산)의 패턴을 간결하게 표현하는 주성분 변수를 원래 변수의 선형 결합으로 추출하는 통계기법이다.

  - 특징

    주성분 변수는 원래 변수 정보를 축약한 변수이며, 일부 주성분에 의해 원래 변수의 변동이 충분히 설명되는지 알아보는 분석 방법이다.

    P개의 변수가 있는 경우 이를 통해 얻은 정보를 P보다 상당히 적은 K개의 변수로 요약하는 것이다.

- 스피어만 순위 상관분석

  - 범주형 데이터 중에서 순서적 데이터에 해당
  - 데이터 순서에 의미를 부여한 데이터 변수 (예. 성적 순위(1, 2, 3등), 학력(고졸, 중졸, 대졸))
  - 변수의 연산이 불가능 (예. 고졸 + 중졸 = 대졸 로 표현 불가능)

- 피어슨 상관계수

  - 수치형 - 수치형 데이터 분석
  - 수치로 표현할 수 있는 측정 가능한 데이터 변수 ( 예. 나이, 몸무게, 이동 거리)
  - 변수의 연산이 가능 ( 예. 이동거리의 평균)
  - 수치적 데이터 변수로 이루어진 두 변수 간의 선형적 연관성을 계량적으로 파악하기 위한 통계적 기법은 피어슨 상관계수이다.

- 로지스틱 회귀분석

  - 회귀 분석(Regression Analysis)개념 : 하나 이상의 독립변수들이 종속변수에 미치는 영향을 추정할 수 있는 통계기법





### 31. 다음 중 연속확률분포를 설명한 것으로 가장 적절한 것은 무엇인가?

1. 정규 분포 함수에서 X를 Z로 정규화한 분포를 카이제곱 분포라고 한다.
2. 모집단이 정규 분포이고, 모 표준편차(&sigma;)는 모를 때 Z-분포를 사용한다.
3. 독립적인 $X$<sup>2</sup>-분포가 있을 때, 두 확률변수의 비는 $F$-분포이다.
4. 모평균이 &mu;, 모분산이 &sigma;<sup>2</sup>이라고 할 때, 종 모양의 분포는 $T$-분포이다.



- 정규 분포 함수에서 $X$를 $Z$로 정규화한 분포는 표준 정규분포이다.
- 모집단이 정규 분포라는 정도만 알고, 모 표준편차(&sigma;)는 모를 때에는 $T$-분포를 사용한다.
- 모평균이 &mu;, 모분산이 &sigma;<sup>2</sup>이라고 할 때, 종 모양의 분포는 정규 분포이다.
- 독립적인 $X$<sup>2</sup>- 분포가 있을 때, 두 확률변수의 비는 $F$-분포이다.



### 33. 다음 중 표본의 정보로부터 모집단의 모수를 하나의 값으로 추정하는 점 추정의 조건으로 가장 부적절한 것은 무엇인가?

1. 불편성(Unbiasedness), 2.사용성(Usability) 3.일치성(Consistency) 4.충족성(Sufficient)



- 점 추정은 표본의 정보로부터 모집단의 모수를 하나의 값으로 추정하는 것이다.
- 점추정 조건 : 불효일충(불편성 / 효율성 / 일치성 / 충족성)



### 36. 다음 중 제1종 오류를 설명한 것으로 가장 적절한 것은 무엇인가?

1. 귀무가설이 참인데 이를 채택하는 결정
2. 귀무가설이 참이 아닌데 이를 채택하지 않는 결정
3. 귀무가설이 참인데 이를 기각하는 결정
4. 귀무가설이 참이 아닌데 이를 채택하는 결정



- 귀무가설이 참인데 잘못하여 기각하게 되는 것은 제1종 오류이다.



### 38. 다음 중 $T$-분포를 설명한 것으로 가장 부적절한 것은 무엇인가?

1. 정규 분포의 평균(&mu;)의 해석에 많이 쓰이는 분포이다.
2. 모집단이 정규 분포라는 정도만 알고, 모 표준편차(&sigma;)는 모를 때 사용한다.
3. 독립적인 카이제곱 분포가 있을 때, 두 확률변수의 비이다.
4. $T$-분포에서는 자유도가 표본의 수인 $n$보다 1적은 $n-1$ 이 된다.



- 독립적인 카이제곱 분포가 있을 때, 두 확률변수의 비는 $F-$분포이다.



### 39. 확률분포는 확률변수의 종류에 따라 크게 이산확률분포와 연속확률분포가 있고 이산확률분포는 이산확률변수 $X$가 가지는 확률분포이다. 다음 중 이산확률분포 종류가 아닌 것은 무엇인가?

1. 베르누이 분포 2.이항분포 3.포아송 분포 4.$T-$분포 



- 이산확률 분포 : 포베이 (포아송 / 베르누이 / 이항분포)
- T-분포는 연속확률분포이다.


### 41. 시계열 데이터는 관측치가 시간적 순서를 가지며 이러한 데이터를 통해 미래의 값을 예측하는 기법을 시계열 분석이라고 한다. 다음 중 시계열 데이터 분석기법의 종류가 아닌 것은 무엇인가?

1. 분해법 2.지수 평활법 3.ARIMA 모델 4.응집분석법



- 응집분석법은 각 객체를 하나의 소집단으로 간주하고 단계적으로 유사한 소집단들을 합쳐 새로운 소집단을 구성하는 것으로 군집 방법이다.
- 4





### 46.  다음 중 회귀 모형의 가정으로 가장 부적합한 것은 무엇인가?

1. 선형성 2.등분산성, 3.정상성 4.일관성



- 회귀 모형은 데이터가 선형성, 독립성, 등분산성, 비상관성, 정상성의 가정을 만족시킬 수 있어야 한다.
- 회귀모형가정 : 선등독비정(선형성,등분산성, 독립성, 비상관성, 정상성)
- 4



### 49. 다음 중 의사결정나무의 구성요소를 설명한 것으로 옳지 않은 것은 무엇인가?

1. 뿌리 마디(Root Node)는 시작되는 마디로 전체 자료를 포함한다.
2. 가지(Branch)는 뿌리 마디로부터 끝마디까지 연결된 상태의 마디들이다.
3. 깊이(Depth)는 뿌리 마디부터 끝마디까지의 부모 마디들의 수이다.
4. 자식 마디(Child Node)는 하나의 마디로부터 분리되어 나간 2개 이상의 마디들이다.



- 깊이(Depth)는 뿌리 마디부터 끝마디까지의 중간 마디들의 수이다.
- 3



### 51. 인공신경망은 입력값을 받아서 출력값을 만들기 위해 활성화 함수를 사용한다. 다음 중 인공신경망의 활성화 함수를 설명한 것으로 가장 부적절한 것은 무엇인가?

1. 활성화 함수는 순 입력함수로부터 전달받은 값을 출력값으로 변환해 주는 함수이다.
2. 활성화 함수에는 계단함수, 부호함수, 선형함수, 시그모이드 함수, tanh 함수, ReLU 함수가 있다.
3. 인공신경망은 입력값을 받아서 출력값을 만들기 위해 활성화 함수를 사용한다.
4. ReLU는 $x$값이 증가하면 $y$값도 지속적으로 증가한다.



- ReLU는 $x$값이 0보다 큰 경우에만 $y$값도 지속적으로 증가한다.
- 4



### 52. 다음 중 퍼셉트론을 설명한 것으로 가장 부적절한 것은 무엇인가?

1. 입력층과 출력층으로만 구성된 최초의 인공신경망이다.
2. 퍼셉트론은 XOR를 선형 분리할 수 없는 문제로 다층 퍼셉트론을 통해 XOR를 선형 분리가 가능해졌다.
3. 퍼셉트론은 입력값, 가중치, 순 입력함수, 활성함수, 출력값으로 되어 있다.
4. 퍼셉트론에 입력층(Input Layer)을 다층으로 하여 만든 것이다.



- 퍼셉트론에 은닉층(Hidden Layer)을 다층으로 하여 만든 것은 다층 퍼셉트론이다.
- 4


### 53. 서포트 벡터 머신(SVM)은 기계학습의 한 분야로 사물 인식, 패턴 인식, 손 글씨 숫자 인식 등 다양한 분야에서 활용되고 있는 지도학습 모델이다. 다음 중 서포트 벡터 머신을 설명한 것으로 가장 적절하지 않은 것은 무엇인가?

1. 서포트 벡터(Support Vector)는 학습 데이터 중에서 결정 경계와 가장 가까이에 있는 데이터들의 집합이다.
2. 결정 경계(Decision Boundary)는 데이터 분류의 기준이 되는 경계이다.
3. SVM은 훈련 시간이 상대적으로 빠르고 다른 방법보다 과대 적합의 가능성이 높은 모델이다.
4. SVM은 공간상에서 최적의 분리 초평면(Hyper-plane)을 찾아서 분류 및 회귀를 수행한다.



- SVM은 훈련 시간이 상대적으로 느리지만, 정확성이 뛰어나며 다른 방법보다 과대적합의 가능성이 낮은 모델이다.
- 3



### 54. 연관성 분석으로 어떤 상품을 고객에게 판매해야 하는지를 예측하려고 한다. 다음은 고객의 영수증 데이터를 확인하여 집계한 결과이다. 사과를 구매한 고객 중에서 우유를 구매한 고객의 신뢰도는 얼마인가?

| 판매품목             | 판매 건수 |
| -------------------- | --------- |
| 사과                 | 4,000     |
| 우유                 | 2,000     |
| 사과, 우유 동시 구매 | 1,000     |
| 전체 거래량          | 10,000    |

1. 10%   2.20%  3.25%  4.30%



- 지지도 : 전체 거래 중 사과, 우유를 모두 구매한 고객의 비율 = 사과 교집합 우유 / 전체 거래수 = 1000 / 10000 = 10%
- 신뢰도 : 사과를 구매한 고개 중 우유를 구매한 고객의 비율 = 사과 교집합 우유 / 사과 = 1000 / 4000 + 1000 = 20%
- 2



### 56. 다음 중 시계열 분석에서 시점에 상관없이 시계열의 특성이 일정하다는 것은 무엇인가?

1. 신속성 2.적합성, 3.유의성 4.정상성



- 시계열분석을 위해서는 정상성을 만족해야 한다.
- 정상성(Stationary)은 시점에 상관없이 시계열의 특성이 일정하다는 의미이다.
- 4





### 58. 다음 중 비정형 데이터 분석기법에 대한 설명으로 가장 부적절한 것은 무엇인가?

1. 사회 연결망 분석(SNA)은 그룹에 속한 사람들간의 네트워크 특성과 구조를 분석하고 시각화하는 분석기법이다.
2. 오피니언 마이닝(Opinion Mining)은 비정형화된 로그 데이터에서 정보를 수집하는 기법이다.
3. 웹 마이닝(Web Mining)은 웹에서 발생하는 고객의 행위 분석과 특성 데이터를 추출, 정제하여 의사결정에 활용하기 위한 기법이다.
4. 텍스트 마이닝(Text Mining)은 텍스트 형태로 이루어진 비정형 데이터들을 자연어 처리방식을 이용해 정보를 추출하는 기법이다.



- 오피니언 마이닝(Opinion Mining)은 주관적인 의견이 포함된 데이터에서 사용자가 게재한 의견과 감정을 나타내는 패턴을 분석하는 기법이다.
- 긍정, 부정, 중립으로 선호도를 판별할 때 사용한다.
- 2





### 59. 다음 앙상벌 기법 중 학습 데이터에서 다수의 부트스트랩(Bootstrap) 자료를 생성하고, 각 자료를 모델링한 후 결합하여 최종 예측 모형을 만드는 것은 무엇인가?

1. 배깅(Begging) 2. 부스팅(Boosting) 3.랜덤 포레스트(Random Forest) 4.스태킹(Stacking)



- 배깅(Bagging: Bootstrap Aggregating)의 개념
    - 학습 데이터에서 다수의 부트스트랩 자료를 생성하고, 각 자료를 모델링한 후 결합하여 최종 예측 모형을 만드는 알고리즘이다.
    - 부트스트랩은 주어진 자료에서 동일한 크기의 표본을 랜덤 복원추출로 뽑은 자료를 의미한다.
- 부스팅(Boosting)의 개념
    - 잘못 분류된 개체들에 가중치를 적용, 새로운 분류 규칙을 만들고, 이 과정을 반복해 최종 모형을 만드는 알고리즘이다.
    - 예측력이 약한 모형(Weak Learner)들을 결합하여 강한 예측 모형을 만드는 방법이다.
- 랜덤 포레스트(Random Forest)의 개념
    - 랜덤 포레스트는 의사결정나무의 특징인 분산이 크다는 점을 고려하여 배깅과 부스팅보다 더 많은 무작위성을 주어 약한 학습기들을 생성한 후 이를 선형 결합하여 최종 학습기를 만드는 방법이다.
    - 랜덤 포레스트 패키지는 랜덤 입력(Random Input)에 따른 여러 트리의 집합인 포레스트(Forest)를 이용한 분류 방법이다.
- 부트스트랩은 주어진 자료에서 동일한 크기의 표본을 랜덤복원추출로 뽑은 자료를 말한다.
- 학습 데이터에서 다수의 부트스트랩 자료를 생성하고, 각 자료를 모델링한 후 결합하여 최종 예측 모형을 만드는 알고리즘은 배깅이다.
- 1



다시 59까지
