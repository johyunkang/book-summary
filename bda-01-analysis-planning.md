# 빅데이터분석기사 2021

## 1 빅데이터 분석 기획

### CHAPTER01 빅데이터의 이해

#### 1 빅데이터 개요 및 활용

##### 1) 빅데이터 특징

###### (1) 빅데이터(Big Data) 개념

- 빅 데이터는 막대한 양(수십 테라바이트 이상)의 정형 및 비정형 데이터이다.
- 데이터로 부터 가치를 추출하고 결과를 분석하는 기술의 의미로도 통용된다.
- 데이터에서부터 가치를 추출하는 것은 통찰, 지혜를 얻는 과정으로 Ackoff, R.L. 이 도식화한 DIKW 피라미드로 표현할 수 있다.

DIKW 피라미드

1. 데이터(Data)
   - 객관적 사실로서 다른 데이터와의 상관관계가 없는 가공하기 전의 순수한 수치나 기호
   - 예) 수제비 책을 A사이트에서 30,000원, B사이트에서 35,000원에 판매
2. 정보(Information)
   - 가공, 처리하여 데이터 간의 연관 관계와 함께 의미가 도출된 데이터
   - 예) 수제비 책은 A 사이트에서 더 싸게 판매
3. 지식(Knowledge)
   - 획득한 다양한 정보를 구조화하여 유의미한 정보로 분류하고 일반화시킨 결과물
   - 정보에 기반해 찾아진 규칙
   - 예) A 사이트가 싸게 팔기 때문에 수제비 책을 구입할 계획
4. 지혜(Wisdom)
   - 근본 원리에 대한 깊은 이해를 바탕으로 도출되는 창의적 아이디어
   - 상황이나 맥락에 맞게 규칙을 적용하는 요소
   - 예) A 사이트의 다른 상품들도 B 사이트보다 저렴할 것으로 판단

데이터 양을 측정하는 바이트 크기

- 킬로(KB, 10<sup>3</sup> Bytes) > 메가(MB, 10<sup>6</sup> Bytes) > 기가(GB, 10<sup>9</sup> Bytes) > 테라(TB, 10<sup>12</sup> Bytes) > 페타(PB, 10<sup>15</sup> Bytes) > 엑사(EB, 10<sup>18</sup> Bytes) > 제타(ZB, 10<sup>21</sup> Bytes) > 요타(YB, 10<sup>24</sup> Bytes)

###### (2) 빅데이터 특징

전통적으로 3V(Volume, Variety, Velocity)의 특징이 있지만, 최근엔 5V(Veracity, Value 추가), 7V(Validity, Volatility 추가)로 확장되고 있다.

빅데이터의 특성

1. 규모(Volume)
   - 빅데이터 분석 규모에 관련된 특징
   - ICT 기술 발전으로 과거의 텍스트 데이터부터 SNS로부터 수집되는 사진, 동영상 등의 다양한 멀티미디어 데이터까지 디지털 정보량의 기하급수적 증가
2. 다양성(Variety)
   - 빅데이터 자원 유형에 관련된 특징
   - 정형 데이터뿐만 아니라 비정형, 반정형 데이터를 포함
3. 속도(Velocity)
   - 빅데이터 수집.분석.활용 속도에 관련된 특징
   - 사물 정보(센서, 모니터링), 스트리밍 정보 등 실시간성 정보의 생성 속도 증가에 따라 처리 속도 가속화 요구
   - 가치 있는 정보 활용을 위해 데이터 처리 및 분석 속도의 중요성 증가
4. 신뢰성(Veracity)
   - 빅데이터 수집 대상 데이터가 가지는 신뢰에 관련된 특징
   - 방대한 데이터에서 노이즈 및 오류 제거를 통해 활용 데이터에 대한 품질과 신뢰성 제고 요구
5. 가치(Value)
   - 빅데이터 수집 데이터를 통해 얻을 수 있는 가치
   - 비즈니스나 연구에 활용되어 유용한 가치를 끌어낼 수 있는가에 대한 문제
   - 빅데이터의 가치는 데이터의 정확성 및 시간성과 관련됨
6. 정확성(Validity)
   - 빅데이터의 수집 대상 데이터가 가지는 유효성과 정확성
   - 데이터의 규모가 아무리 크더라도 질 높은 데이터를 활용한 정확한 분석 수행이 없다면 의미가 없음
   - 데이터가 타당한지 정확한지에 대한 여부는 의사결정의 중요한 요소
7. 휘발성(Volatility)
   - 빅데이터의 수집 대상 데이터가 의미가 있는 기간
   - 데이터가 얼마나 오래 저장될 수 있고, 타당하여 오랫동안 쓰일 수 있을지에 관한 사항
   - 빅데이터는 장기적인 관점에서 유용한 가치를 창출해야 함

###### (3) 빅데이터의 유형

데이터 구조적 관점에서의 빅데이터 유형

1. 정형
   - 정형화된 스키마 구조, DBMS에 내용이 저장될 수 있는 구조
   - 고정된 필드(속성)에 저장된 데이터
   - 예) 관계형 데이터베이스(Oracle, MS-SQL 등)
2. 반정형
   - 데이터 내부의 데이터 구조에 대한 메타 정보가 포함된 구조
   - 고정된 필드에 저장되어 있지는 않지만, 메타데이터나 데이터 스키마 정보를 포함하는 데이터
   - 예) XML, HTML, JSON 등
3. 비정형
   - 수집 데이터 각각이 데이터 객체로 구분
   - 고정 필드 및 메타데이터(스키마 포함)가 정의되지 않음
   - Crawler, API, RSS 등의 수집 기술을 활용
   - 예) 텍스트 문서, 이진 파일, 이미지, 동영상 등

###### (4) 데이터 지식경영

데이터 기반 지식경영의 핵심 이슈는 암묵지와 형식지의 상호작용에 있다.

1. 암묵지
   - 학습과 경험을 통해 개인에게 체화되어 있지만 겉으로 드러나지 않는 지식
   - 사회적으로 중요하지만 다른 사람에게 공유되기 어려움
   - 예) 수영, 태권도
   - 상호작용 : 공통화, 내면화
2. 형식지
   - 문서나 매뉴얼처럼 형상화된 지식
   - 전달과 공유가 용이
   - 예) 수험서, 소프트웨어 설치 매뉴얼
   - 상호작용 : 표출화, 연결화

데이터 지식경영 상호작용

1. 내면화 : 행동과 실천교육 등을 통해 형식지가 개인의 암묵지로 체화되는 단계
2. 공통화 : 다른 사람과의 대화 등 상호작용을 통해 개인이 암묵지를 습득하는 단계
3. 표출화 : 형식지 요소 중의 하나이며 개인에게 내재된 경험을 객관적인 데이터인 문서나 매체로 저장하거나 가공, 분석하는 과정
4. 연결화 : 형식지가 상호결합하면서 새로운 형식지를 창출하는 과정


##### 2) 빅데이터의 가치

###### (1) 빅데이터의 가치

- 경제적 자산

  - 새로운 기회를 창줄하고, 위험을 해결하여 사회 및 경제 발전의 엔진 역할을 수행

- 불확실성 제거

  - 사회현상, 현실 세계의 데이터를 기반으로 한 패턴 분석과 미래 전망
  - 여러 가지 가능성에 대한 시나리오 시뮬레이션

- 리스크 감소

  - 환경, 소설, 모니터링 정보의 패턴 분석을 통해 위험 징후 및 이상 신호 포착
  - 이슈를 사전에 인지 및 분석하고 빠른 의사 결정과 실시간 대응

- 스마트한 경쟁력

  - 대규모 데이터 분석을 통한 상황 인지, 인공지능 서비스 기능
  - 개인화, 지능화 서비스 제공 확대
  - 트렌드 변화 분석을 통한 제품 경쟁력 확보

- 타 분야 융합

  - 타 분야와의 융합을 통한 새로운 가치 창출

  - 방대한 데이터 활용을 통한 새로운 융합시장 창출



###### (2) 빅데이터 가치 산정이 어려운 이유

- 데이터 활용 방식의 다양화
  - 데이터의 재사용, 데이터의 재조합, 다목적용 데이터 개발 등이 일반화되면서 특정 데이터를 언제/어디서/누가 활용할지 알 수 없어서 가치 산정이 어려움
  - 데이터의 창의적 조합으로 인해 기존에 풀 수 없는 문제를 해결하는데 도움을 주기 때문에 가치 산정이 어려움
  - 예) 구글이 검색 결과를 낼 때마다 구글은 클라우드에 저장된 웹 사이트 정보를 매번 사용
- 새로운 가치 창출
  - 빅데이터 시대에 데이터가 기존에 없던 가치를 창출하여 가치 산정이 어려움
  - 예) 고객의 성향을 분석하여 고객 맞춤 서비스 제공
- 분석기술의 급속한 발전
  - 비용 문제로 분석할 수 없었던 것을 저렴한 비용으로 분석하면서 활용도가 증가하여 가치 산정이 어려움
  - 예) 텍스트 마이닝을 통한 SNS 분석



###### (3) 빅데이터 영향

- 기업 : 혁신 수당 제공, 경쟁력 강화, 생산성 향상
- 정부 : 환경 탐색, 상황 분석, 미래 대응 가능
  - 예) 사회관계망 분석, 시스템 다이내믹스와 같은 분석 방식을 통해 미래 의제 도출
  - 사회관계망 분석(**SNA**; Social Network Analysis) : 그룹에 속한 사람들 간의 네트워크 특성과 구조를 분석하고 시각화하는 분석기법
  - 시스템 다이내믹스(System Dynamics) : 사업이나 사회 시스템 등과 같은 복잡한 피드백 시스템을 연구하고 관리하는 방법이다.
- 개인 : 목적에 따른 활용
  - 예) 빅데이터 서비스를 저렴한 비용으로 활용. 적시에 필요한 정보를 획득



###### (4) 빅데이터 위기 요인 및 통제 방안

빅데이터 위기요인

- 사생활 침해
- 책임 원칙 훼손
- 데이터 오용

빅데이터 위기 요인에 대한 통제 방안

- 알고리즘에 대한 접근 허용
- 책임의 강조
- 결과 기반의 책임 적용



##### 3) 빅데이터 산업의 이해

###### (1) 빅데이터 산업 개요

- 스마트폰, SNS, IoT 확산 등에 따라 데이터 활용이 증가하여 빅데이터는 신성장동력으로 급부상 중
- 클라우드 컴퓨팅 기술의 발전으로 데이터 처리 비용이 급격히 감소하여 빅데이터가 발전 중
- 주요국 및 글로벌 기업은 빅데이터 '산업' 육성 및 '활용'에 주력 중
- 우리나라는 데이터 생산량이 많은 산업(통신.제조업 등)이 발달해 잠재력이 크지만, 불확실성에 따른 투자 리스크 등으로 '활용'은 저조하다

###### (2) 산업별 빅데이터 활용

- 의료.건강
- 과학기술
- 정보보안
- 제조.공정
- 소비.거래
- 교통.물류



##### 4) 빅데이터 조직 인력

###### (1) 빅데이터 조직 설계

빅데이터 업무 프로세스

1. 빅데이터 도입 단계
   - 빅데이터 서비스를 제공하기 위해서는 빅데이터 시스템 구축을 위한 빅데이터 도입 기획, 기술 검토, 도입 조직 구성, 예산 확보 등을 수행
1. 빅데이터 구축 단계
   - 빅데이터 플랫폼을 구축하기 위해서는 요구사항 분석, 설계, 구현, 테스트 단계를 수행
1. 빅데이터 운영 단계
   - 빅데이터 시스템의 도입 및 구축이 끝나면, 이를 인수하여 운영 계획을 수립
   - 빅데이터 플랫폼 운영, 데이터 및 빅데이터 분석 모델 운영, 빅데이터 운영 조직, 운영 예산 고려



###### (2) 조직 역량

데이터 사이언티스트의 요구역량

- 소프트 스킬(Soft Skill)
  - 분석의 통찰력 : 논리적 비판 능력, 창의적 사고력, 호기심
  - 여러 분야의 협력 능력 : 커뮤니케이션 능력
  - 설득력 있는 전달력 : 스토리텔링 능력, 비쥬얼라이제이션
- 하드 스킬(Hard Skill)
  - 빅데이터 관련 이론적 지식 : 빅데이터 관련 기법 및 다양한 방법론 습득
  - 분석기술의 숙련도 : 목적에 맞는 최적 분석 설계, 노하우 축적

가트너(Gartner)는 데이터 사이언티스트가 갖추어야 할 역량으로 분석 모델링, 데이터 관리, 소프트 스킬, 비즈니스 분석을 제시했다.



역량 모델 개발 절차

1. 조직의 미션/성과 목표/CSF 검토 : 조직이 구성되면 조직의 미션, 조직의 성과 목표를 달성하기 위하여 CSF를 검토

> **CSF**(Critical Success Factor; 핵심 성공 요인) : 목표 성취를 위해 필요한 요소를 뜻하는 용어로 기업 경쟁력 향상을 위한 핵심 내부 역량이며, 목표 달성을 위해 반드시 수행해야 하는 필수 요소이다.

2. 조직 구성원의 행동 특성 도출 : 성과 목표 달성을 잘하는 우수 성과자의 행동 특성을 파악하여 도출
1. 조직 구성원의 역량 도출 : 도출된 행동 특성을 기반으로 지식, 스킬, 태도 등을 도출하여 직무별 역량 모델을 생성
1. 조직 구성의 역량 모델 확정 : 직무별 역량 모델을 업무 전문가, 인사 담당자가 검토하고 협의하여 확정



역량 교육 체계 설계 절차

1. 요구사항 분석
1. 직무별 역량 모델 검토
1. 역량 차이 분석
1. 직무 역량 매트릭스 작성
1. 직무별 역량 교육 체계 설계



###### (3) 조직성과 평가

> **KPI**(Key Performance Indicator; 핵심 성과 지표) : 사업, 부서, 혹은 개인 차원의 목표가 달성되었는지 그 실적을 추적하기 위한 정량화된 측정 지표이다. (예를 들어 1인당 1년에 30개의 카드 발급 추진)

조직성과 평가 절차

1. 목표 설정
2. 모니터링
3. 목표 조정
4. 평가 실시
5. 결과의 피드백



균형 성과표(**BSC**; Balanced Score Card) 4가지 관점

- 재무 : 기업의 주요 이해 관계자들에게 재무적인 지표를 통해 조직의 성과를 보여주기 위한 관점
- 고객 : 고객 관계 관리를 위한 관점. 기업에 수익을 가져다줄 수 있는 고객을 파악해 내고, 이들을 위한 고객 지향적 프로세스를 만들어나가는 것이 고객 관계 관리의 핵심 성공 요인
- 내부 프로세스 : 성과를 극대화하기 위하여 기업의 핵심 프로세스 및 핵심 역량을 규명하는 과정에 관련한 관점
- 학습.성장 : BSC의 4가지 관점 중에서 가장 미래 지향적인 관점. 현재에는 그 가치가 보이지 않지만, 회사의 장기적인 잠재력에 대한 투자가 기업 성정에 얼마나 영향을 미칠 수 있을지를 파악



BSC를 통한 KPI 도출 예시

|     관점      | KPI 지표                      | KPI 목표               | 계산방식(단위)               | 평가기준                             |
| :-----------: | ----------------------------- | ---------------------- | ---------------------------- | ------------------------------------ |
|     재무      | 빅데이터 분석비용 절감        | 10% 절감               | 전년 대비 분석비용 절감률(%) | 1등급 :10% 이상<br>2등급 : 5% 이상   |
|     고객      | 빅데이터 서비스 만족도        | 별 5점 만점에 4점 이상 | 고객 평가 점수(점)           | 1등급 : 평균 4점<br>2등급 : 평균 3점 |
| 내부 프로세스 | 서비스 가동률                 | 99% 가용성 확보        | 서비스 가동률(%)             | 1등급 : 99%<br>2등급 : 98%           |
|   학습.성장   | 1인당 빅데이터 분석 교육 시간 | 1인당 24시간 이상      | 교육 시간(시간)              | 1등급 : 24시간<br>2등급 : 16시간     |



#### 2 빅데이터 기술 및 제도

##### 1) 빅데이터 플랫폼

###### (1) 빅데이터 플랫폼(Bigdata Platform)의 개념

- 빅데이터에서 가치를 추출하기 위해 일련의 과정(수집 > 저장 > 처리 > 분석 > 시각화)을 규격화한 기술이다.

###### (2) 빅데이터 플랫폼 구성요소

|  구성요소   | 주요기능                                                     |
| :---------: | :----------------------------------------------------------- |
| 데이터 수집 | 원천 데이터의 정형/반정형/비정형 데이터 수집<br>ETL, 크롤러, EAI(Enterprise Architecture Integration) 등 |
| 데이터 저장 | 정형 데이터, 반정형 데이터, 비정형 데이터 저장<br>RDBMS, NoSQL 등 |
| 데이터 분석 | 텍스트 분석, 머신러닝, 통계, 데이터 마이닝<br>SNS 분석, 예측 분석 등 |
| 데이터 활용 | 데이터 가시화 및 BI, Open API 연계<br>히스토그램, 인포그래픽 등 |

용어설명

> **크롤러**(Crawler) : URL에 존재하는 HTML 문서에 접근하여 해당 내용을 추출하고, 문서에 포함된 하이퍼링크를 통해 재귀적으로 다른 문서에 접근하여 콘텐츠 수집을 반복하는 기술
>
> **EAI**(Enterprise Architecture Integration) : 기업에서 운영하는 서로 다른 기종의 애플리케이션 및 시스템을 통합하는 솔루션
>
> **NoSQL**(Not Only SQL) : NoSQL은 전통적인 RDBMS와 다른 DBMS를 지칭하기 위한 용어로서 데이터 저장에 고정된 테이블 스키마가 필요하지 않고 조인(Join) 연산을 사용할 수 없으며, 수평적 확장이 가능한 DBMS 이다.
>
> **BI**(Business Intelligence) : 데이터를 통합/분석하여 기업 활동에 연관된 의사결정을 돕는 프로세스이다.
>
> **히스토그램**(Histogram) : 자료 분포의 형태를 직사각형 형태로 시각화하여 보여주는 차트, 수평축에는 각 계급을 나타내고, 수직축에는 도수 또는 상대도수를 나타낸다.
>
> **인포그래픽**(Infographics) : 인포그래픽은 Information + Graphic의 줄임말. 중요 정보를 하나의 그래픽으로 표현해서 보는 사람들이 쉽게 정보를 이해할 수 있도록 만드는 시각화 방법



###### (3) 빅데이터 플랫폼 데이터 형식

* HTML
  * HyperText Markup Language 약자
  * 웹 페이지를 만들 때 사용되는 문서 형식
  * 텍스트, 태그, 스크립트로 구성
* XML
  * eXtensible Markup Language의 약자
  * SGML 문서 형식을 가진, 다른 특수한 목적을 갖는 마크업 언어를 만드는데 사용하는 다목적 마크업 언어
  * 데이터 표현을 위해 태그 사용
  * 엘리먼트, 속성, 처리 명령, 엔티티, 주석, CDATE 섹션으로 구성
* CSV
  * Comma Separated Values의 약자
  * 몇 가지 필드를 쉼표(,)로 구분한 텍스트 데이터 및 텍스트 파일
* JSON
  * JavaScript Object Notation의 약자
  * <키-값>으로 이루어진 데이터 오브젝트를 전달하기 위해 텍스트를 사용하는 개방형 포맷



###### (4) 빅데이터 플랫폼 구축 소프트웨어

| 소프트웨어  |       핵심        | 목적                                                         |
| :---------: | --------------- | ------------------------------------------------------------ |
|      R      |   빅데이터 분석   | 통계 프로그래밍 언어인 S 언어를 기반으로 만들어진 오픈소스 프로그래밍 언어<br>다양한 그래프 패키지들을 통하여 강력한 시각화 기능 제공 |
| 우지(Oozie) |  워크플로우 관리  | 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템(스케줄링/모니터링)<br>맵리듀스나 피그와 같은 특화된 액션들로 구성된 워크플로우 제어 |
| 플럼(Flume) |    데이터 수집    | 이벤트와 에이전트(Agent)를 활용하여 많은 양의 로그 데이터를 효율적으로 수집, 집계, 이동 |
|    HBase    | 분산 데이터베이스 | 컬럼 기반 저장소로 HDFS와 인터페이스 제공                    |
| 스쿱(Sqoop) | 정형 데이터 수집  | 'SQL to Hadoop'의 약자<br>커넥터(Connector)를 사용하여 RDBMS 에서 하둡 파일 시스템(HDFS)으로 데이터를 수집하거나, HDFS에서 RDBMS로 데이터를 보내는 기능 수행 |



분산 컴퓨팅 환경 소프트웨어 구성요소

- 맵리듀스(Map Reduce)
  - Key - Value 형태의 데이터 처리
  - 맵(Map) > 셔플(Shuffle) > 리듀스(Reduce) 순서대로 데이터 처리
    - 맵 : Key - Value 형태로 데이터를 취합
    - 셔플 : 데이터를 통합하여 처리
    - 리듀스 : 맵 처리된 데이터를 정리
- 얀 (YARN)
  - 하둡의 맵리듀스 처리 부분을 새롭게 만든 자원 관리 플랫폼
  - 리소스 매니저(Master)와 노드 매니저(Slave)로 구성
    - 리소스 매니저 : 스케줄러 역할을 수행하고 클러스터 이용률 최적화를 수행
    - 노드 매니저 : 노드 내의 자원을 관리하고 리소스 매니저에게 전달 수행 및 컨테이너를 관리
    - 애플리케이션 마스터 : 리소스 매니저와 자원의 교섭을 책임지고, 컨테이너를 실행
    - 컨테이너 : 프로그램 구동을 위한 격리 환경을 지원하는 가상화 자원
- 아파치 스파크(Apache Spark)
  - 하둡 기반 대규모 데이터 분산처리시스템
  - 스트리밍 데이터, 온라인 머신러닝 등 실시간 데이터 처리
  - 스칼라, 자바, 파이썬, R 등에 사용
- 하둡 분산 파일 시스템(HDFS)
  - Hadoop Distributed File Sytem 의 약자
  - 대용량 파일을 분산된 서버에 저장하고, 그 저장된 데이터를 빠르게 처리할 수 있게 하는 하둡 분산 파일 시스템
  - 네임 노드(Master)와 데이터 노드(Slave)로 구성
    - 네임 노드 : 파일 이름, 권한 등의 속성 기록
    - 데이터 노드 : 일정한 크기로 나눈 블록 형태로 저장
- 아파치 하둡 (Apache Hadoop)
  - 분산 파일 시스템(HDFS)과 맵리듀스를 중심으로 다양한 프로그램으로 구성된 하둡 에코시스템을 가짐
  - 클라우드 플랫폼 위에서 클러스터를 구성해 데이터 분석
  - 예) Spark, Hive, YARN, Cassandra, Pig 등



###### (5) 하둡 에코시스템(Hadoop Ecosystem)

하둡 프레임워크를 이루고 있는 다양한 서브 프로젝트들의 모임

하둡 에코시스템 수집, 저장, 처리 기술

- 비정형 데이터 수집
  - 척와(Chukwa) : 분산된 각 서버에서 에이전트를 실행하고, 컬렉터(Collector)가 에이전트로부터 데이터를 받아 HDFS에 저장
  - 플럼(Flume) : 많은 양의 로그 데이터를 효율적으로 수집, 집계, 이동하기 위해 이벤트와 에이전트(Agent)를 활용하는 기술
  - 스크라이브(Scribe)
    - 다수의 서버로부터 실시간으로 스트리밍되는 로그 데이터를 수집하여 분산 시스템에 데이터를 저장하는 대용량 실시간 로그 수집 기술
    - 최종 데이터는 HDFS 외에 다양한 저장소를 활용 가능
    - HDFS에 저장하기 위해서는 JNI(Java Native Interface)를 이용
- 정형 데이터 수집
  - 스쿱(Sqoop)
    - 대용량 데이터 전송 솔루션
    - 커넥터를 사용하여 RDBMS에서 HDFS로 데이터를 수집하거나, HDFS에서 RDBMS로 데이터를 보내는 기능 수행
    - Oracle, MS-SQL, DB2와 같은 상용 RDBMS와 MySQL과 같은 오픈소스 RDBMS 지원
  - 히호(Hiho)
    - 스쿱과 같은 대용량 데이터 전송 솔루션이며, 현재 깃허브에서 공개되어 있음
    - 하둡에서 데이터를 가져오기 위한 SQL을 지정할 수 있으며, JDBC 인터페이스를 지원, 현재는 Oracle, MySQL의 데이터만 전송 지원
- 분산 데이터 저장
  - HDFS
    - 대용량 파일을 분산된 서버에 저장하고, 그 저장된 데이터를 빠르게 처리할 수 있게 하는 하둡 분산 파일 시스템
    - 범용 하드웨어 기반, 클러스터에서 실행되고 데이터 접근 패턴을 스트리밍 방식으로 지원
    - 다중 복제, 대량 파일 저장, 온라인 변경, 범용서버 기반, 자동복구 특징이 있음
- 분산 데이터 처리
  - 맵리듀스(Map Reduce)
    - 대용량 데이터 세트를 분산 병렬 컴퓨팅에서 처리하거나 생성하기 위한 목적으로 만들어진 소프트웨어 프레임워크
    - 모든 데이터를 Key - Value 쌍으로 구성, 데이터를 분류
- 분산 데이터 베이스
  - HBase
    - 컬럼 기반 저장소로 HDFS와 인터페이스 제공
    - 실시간 랜덤 조회 및 업데이트를 할 수 있으며, 각각의 프로세스는 개인의 데이터를 비동기적으로 업데이트할 수 있음



하둡 에코시스템의 데이터 가공 및 분석, 관리를 위한 주요 기술

- 데이터 가공
  - 피그(Pig)
    - 대용량 데이터 집합을 분석하기 위한 플랫폼으로 하둡을 이용하여 맵리듀스를 사용하기 위한 높은 수준의 스크립트 언어인 **피그 라틴**이라는 자체 언어를 제공
    - 맵리듀스 API를 매우 단순화시키고, SQL과 유사한 형태로 설계됨
    - SQL과 유사하기만 할 뿐, 기존 SQL 지식을 활용하는 것이 어려움
  - 하이브(Hive)
    - 하둡 기반의 DW(Data Warehouse) 솔루션
    - SQL과 매우 유사한 HiveQL이라는 쿼리를 제공
    - HiveQL은 내부적으로 맵리듀스로 변환되어 실행됨
- 데이터 마이닝
  - 머하웃(Mahout)
    - 하둡 기반으로 데이터 마이닝 알고리즘을 구현한 오픈소스
    - 분류, 클러스터링, 추천 및 협업 필터링, 패턴 마이닝, 회귀 분석, 진화 알고리즘 등 주요 알고리즘 지원
- 실시간 SQL 질의
  - 임팔라(Impala)
    - 하둡 기반의 실시간 SQL 질의 시스템
    - 데이터 조회를 위한 인터페이스로 HiveQL을 사용
    - 수초 내에 SQL 질의 결과를 확인할 수 있으며, HBase와 연동이 가능
- 워크플로우 관리
  - 우지(Oozie)
    - 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템
    - 자바 서블릿 컨테이너에서 실행되는 자바 웹 애플리케이션 서버
    - 맵리듀스나 피그와 같은 특화된 액션들로 구성된 워크플로우 제어
- 분산 코디네이션
  - 주키퍼(Zookeeper)
    - 분산 환경에서 서버들 간에 상호 조정이 필요한 다양한 서비스를 제공
    - 하나의 서버에만 서비스가 집중되지 않도록 서비스를 알맞게 분산하여 동시에 처리
    - 하나의 서버에서 처리한 결과를 다른 서버들과도 동기화하여 데이터의 안정성을 보장

> > 피그 라틴(Pig Latin) : 데이터의 흐름을 표현하기 위해 사용하는 언어이다.


##### 2) 빅데이터와 인공지능 (중요도 하)

###### (1) 인공지능의 개념

인간의 지적능력을 인공적으로 구현하여 컴퓨터가 인간의 지능적인 행동과 사고를 모방할 수 있도록 하는 sw

###### (2) 빅데이터와 인공지능의 관계

- 1950년에 등장한 인공지능을 최신 트렌드로 끌고 온 것은 '빅데이터'의 존재
- 빅데이터는 비정형 데이터를 고속으로 분석할 수 있고, 이러한 점은 인공지능이 기존에 기계가 인지하지 못했던 정보들을 분석할 수 있게 한다.
- **인공지능의 암흑기**를 지나 빅데이터를 통해 자체 알고리즘을 가지고 학습하는 **딥러닝** 기술로 특정 분야에서 인간의 지능을 뛰어넘는 능력을 갖추게 되었다.

> 딥러닝(Deep Learning) : 사람의 개입이 필요한 기존의 지도 학습(Supervised Learning) 보다 더 능동적인 비지도 학습(Unsupervised Learning)이 결합되어 컴퓨터가 마치 사람처럼 스스로 학습할 수 있는 인공지능 기술

###### (3) 빅데이터와 인공지능의 전망

- 상호보완 관계로 빅데이터는 인공지능 구현 완성도를 높여주고, 빅데이터는 인공지능을 통해 문제 해결 완성도를 높인다.
- 빅데이터 기술이 주목받는 이유는 우수한 정보처리를 바탕으로 의미 있는 결과를 도출할 수 있다는 점이다.
- 빅데이터 목표가 인공지능 목표와 부합하고, 인공지능 판단을 위해서는 빅데이터와 같은 기술이 필요하므로, 빅데이터는 인공지능을 위한 기술이 될 가능성이 크다.



##### 3) 개인정보보호법.제도

###### (1) 개인정보보호의 개념

개인정보보호는 정보 주체(개인)의 **개인정보 자기 결정권**을 철저히 보장하는 활동을 의미한다.

> 개인정보 자기 결정권 : 자신에 관한 정보가 언제, 어떻게 그리고 어느 범위까지 타인에게 전달되고 이용될 수 있는지를 그 정보 주체가 스스로 결정할 수 있는 권리

###### (2) 개인정보보호의 필요성

|        필요성        | 세부 내용                                                    |
| :------------------: | ------------------------------------------------------------ |
|  유출 시 피해 심각   | 개인적 피해(정신적/경제적)와 함께 사회적 혼란 야기           |
| 정보사회 핵심 인프라 | 정보사회에서 모든 경제활동의 중심이 개인정보를 매개로 운영   |
| 개인정보 자기 통제권 | 정보 주체는 자신과 관련된 정보의 수집, 이용, 공개, 제공에 대해 본인이 통제할 수 있는 권리가 있음 |


###### (3) 빅데이터 개인정보보호 가이드라인

- 개인정보 비식별화
  - 수집 시부터 개인 식별 정보에 대한 철저한 비식별화 조치
  - 개인정보가 포함된 공개 정보 및 이용 내역 정보는 비식별화 조치를 취한 후 수집, 저장, 조합, 분석 및 제3자 제공 등 가능
- 개인정보 재식별 시 조치
  - 개인정보 재식별 시, 즉시 파기 및 비식별화 조치
  - 빅데이터 처리 과정 및 생성정보에 개인정보가 재식별될 경우, 즉시 파기하거나 추가적인 비식별화 조치 시행
- 민감정보 처리
  - 민감정보 및 통신비밀의 수집, 이용, 분석 등 처리 금지
  - 특정 개인의 사상, 신념, 정치적 견해 등 민감정보의 생성을 목적으로 정보의 수집, 이용, 저장, 조합, 분석 등 처리 금지
  - 이메일, 문자, 메시지 등 통신 내용의 수집, 이용, 저장, 조합분석 등 처리 금지
- 투명성 확보
  - 빅데이터 처리 사실, 목적 등의 공개를 통한 투명성 확보
  - 개인정보 취급방침을 통해 비식별화 조치 후 빅데이터 처리 사실, 목적, 수집 출처 및 정보 활용 거부권 행상 방법 등을 이용자에게 투명하게 공개
  - 개인정보 취급방침
    - 비식별화 조치 후 빅데이터의 처리 사실, 목적 등을 이용자에게 공개
    - <정보 활용 거부 페이지 링크>를 제공하여 이용자가 거부권을 행사할 수 있도록 조치
  - 수집 출처 고지
    - 이용자 이외의 자로부터 수집한 개인정보 처리 시 <수집 출저, 목적, 개인정보 처리 정치 요구권>을 이용자에게 고지
- 수집정보의 **보호조치**
  - 수집된 정보의 저장관리 시 기술적, 관리적 보호조치
  - 비식별화 조치가 취해진 정보를 저장관리하고 있는 정보처리시스템에 대한 기술적, 관리적 보호조치 적용

> 보호조치 : 침입 차단시스템 등 접근 통제장치 설치, 접속 기록에 대한 위.변조 방지 조치, 백신 소프트웨어 설치 운영 등 악성 프로그램에 의한 침해 방지 조치이다.



###### (4) 개인정보보호 관련 법령

|            관련 법규            | 주요 내용                                                    |
| :-----------------------------: | ------------------------------------------------------------ |
|         개인정보 보호법         | 개인정보 처리 과정상의 정보 주체와 개인정보 처리자의 권리, 의무 등 규정 |
|          정보통신망법           | '정보통신망 이용촉진 및 정보보호 등에 관한 법률'의 약칭<br>정보통신망을 통하여 수집, 처리, 보관, 이용되는 개인정보의 보호에 관한 규정 |
|           신용정보법            | '신용정보의 이용 및 보호에 관한 법률'의 약칭<br>개인 신용정보의 취급 단계별 보호조치 및 의무사항에 관한 규정 |
|           위치정보법            | '위치정보의 보호 및 이용 등에 관한 법률'의 약칭<br>개인 위치정보 수집, 이용, 제공 파기 및 정보 주체의 권리 등 규정 |
| 개인정보의 안전성 확보조치 기준 | 개인정보 처리자가 개인정보를 처리함에 있어서 분실, 도난, 유출, 변조, 훼손되지 않도록 안전성을 확보하기 위해 취해야 하는 세부적인 기준 규정<br>개인정보 처리시스템의 보호 수준을 진단, 암호화에 상응하는 조치 필요 여부를 판단할 수 있는 기준을 규정 |

> 개망신법 : 주요 3법인 개인정보보호법, 정보통신망법, 신용정보법을 현업에서 줄여서 표현
>
> 마이 데이터(My Data) : 개인이 자신의 정보를 관리.통제할 뿐만 아니라 이러한 정보를 신용이나 자산관리 등에 능동적으로 활용하는 일련의 과정



###### (5) 개인정보보호 내규

|           내규            | 주요 내용                                                    |
| :-----------------------: | ------------------------------------------------------------ |
|  정보보호 업무처리 지침   | 정보보호 조치, 개인정보 수집, 개인정보 처리 안정성 확보<br>정보보호 시스템 운영 등 각종 행정처리 절차 명사 |
|     개발 보안 가이드      | 소포트웨어 개발 시 보안 약점 제거<br>보안성을 높이는 개발 기법 가이드 마련 |
|  개인정보 암호화 매뉴얼   | 꼭 필요한 최소한의 사용자만 개인정보 접근 허용<br>개인정보 파일 암호화 저장, 사용 |
| 소포트웨어 개발 보안 구조 | 정보보안 통제 구조<br>전체적인 **정보기술 아키텍처**와의 관련성 명시 |
|    기술적, 관리적 보호    | 개인정보의 분실, 도난, 누출, 변조, 훼손 방지 방법 마련       |

> 정보기술 아키텍처(Enterprise Architecture) : 일정한 기준과 절차에 따라 업무, 응용, 데이터, 기술, 보안 등 조직 전체의 정보화 구성요소들을 통합적으로 분석한 뒤 이들 간의 관계를 구조적으로 정리한 체제 및 이를 바탕으로 정보시스템을 효율적으로 구성하기 위한 방법이다





